{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a32f4a0-96ea-48fe-a8ac-fa6adbef7f3e",
   "metadata": {},
   "source": [
    "# Run Agent in Environment with different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37105a1-c06c-445d-b9f9-afc70b8764e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Data \n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import numpy as np\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Algorithms \n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import TD3\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from sb3_contrib import TQC\n",
    "from sb3_contrib import TRPO\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "import torch.nn as nn\n",
    "from rl_zoo3 import linear_schedule\n",
    "\n",
    "from gym import make\n",
    "from gym.envs.registration import register\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "import torch\n",
    "import subprocess\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db6c67-ec11-492b-b29d-773764e7dc09",
   "metadata": {},
   "source": [
    "## Register the Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de7d899-f638-44cf-8c5b-3f80b0723019",
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id=\"VPPBiddingEnv-TRAIN-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"DEBUG\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"training\",\n",
    "            'render_mode' :\"human\", # \"human\", \"fast_training\" or None\n",
    "           }\n",
    ")\n",
    "\n",
    "register(\n",
    "    id=\"VPPBiddingEnv-EVAL-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"DEBUG\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"eval\",\n",
    "            'render_mode' :\"human\", # \"human\", \"fast_training\" or None\n",
    "           }\n",
    ")\n",
    "\n",
    "register(\n",
    "    id=\"VPPBiddingEnv-TEST-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"INFO\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"test\",\n",
    "            'render_mode' :\"human\", # \"human\", \"fast_training\" or None\n",
    "           }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17256e7-0240-435d-a641-55d444a43406",
   "metadata": {},
   "source": [
    "## Test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72671bc0-33dd-4453-81b9-d86c8979a5ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_step: initial // slot: initial  log level = info\n",
      "log_step: initial // slot: initial  log level = warning\n",
      "log_step: 0 slot: None logging_step: 0\n",
      "log_step: 0 slot: None Bid Submission time (D-1) = 2020-07-02 05:00:00+00:00\n",
      "log_step: 0 slot: None Gate Closure time (D-1) = 2020-07-02 06:00:00+00:00\n",
      "log_step: 0 slot: None Historic Data Window: from 2020-07-01 05:00:00+00:00 to 2020-07-02 04:45:00+00:00 \n",
      "log_step: 0 slot: None Forecast Data Window: from 2020-07-02 22:00:00+00:00 to 2020-07-03 21:45:00+00:00 \n",
      "log_step: 0 slot: 0 Current Slot Time: (D) = 2020-07-02 22:00:00+00:00\n",
      "log_step: 0 slot: 0 agents_bid_size = 66\n",
      "log_step: 0 slot: 0 agents_bid_price = 2293.053\n",
      "log_step: 0 slot: 0 settlement_price_DE : 16.67\n",
      "log_step: 0 slot: 0 self.activation_results['slots_won'] = \n",
      "log_step: 0 slot: 0\n",
      "slot won: \t-1 \n",
      "slot won: \tNone \n",
      "slot won: \tNone \n",
      "slot won: \tNone \n",
      "slot won: \tNone \n",
      "slot won: \tNone\n",
      "log_step: 0 slot: 0      agents bid_size = \n",
      "log_step: 0 slot: 0\n",
      "size: \t66 \n",
      "size: \t103 \n",
      "size: \t28 \n",
      "size: \t72 \n",
      "size: \t82 \n",
      "size: \t87\n",
      "log_step: 0 slot: 0 self.activation_results['slot_settlement_prices_DE'] = \n",
      "log_step: 0 slot: 0\n",
      "price: \t16.67 \n",
      "price: \tNone \n",
      "price: \tNone \n",
      "price: \tNone \n",
      "price: \tNone \n",
      "price: \tNone\n",
      "log_step: 0 slot: 1 Current Slot Time: (D) = 2020-07-03 02:00:00+00:00\n",
      "log_step: 0 slot: 1 agents_bid_size = 103\n",
      "log_step: 0 slot: 1 agents_bid_price = 1474.856\n",
      "log_step: 0 slot: 1 settlement_price_DE : 19.06\n",
      "log_step: 0 slot: 1 self.activation_results['slots_won'] = \n",
      "log_step: 0 slot: 1\n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \tNone \n",
      "slot won: \tNone \n",
      "slot won: \tNone \n",
      "slot won: \tNone\n",
      "log_step: 0 slot: 1      agents bid_size = \n",
      "log_step: 0 slot: 1\n",
      "size: \t66 \n",
      "size: \t103 \n",
      "size: \t28 \n",
      "size: \t72 \n",
      "size: \t82 \n",
      "size: \t87\n",
      "log_step: 0 slot: 1 self.activation_results['slot_settlement_prices_DE'] = \n",
      "log_step: 0 slot: 1\n",
      "price: \t16.67 \n",
      "price: \t19.06 \n",
      "price: \tNone \n",
      "price: \tNone \n",
      "price: \tNone \n",
      "price: \tNone\n",
      "log_step: 0 slot: 2 Current Slot Time: (D) = 2020-07-03 06:00:00+00:00\n",
      "log_step: 0 slot: 2 agents_bid_size = 28\n",
      "log_step: 0 slot: 2 agents_bid_price = 1001.41364\n",
      "log_step: 0 slot: 2 settlement_price_DE : 17.72\n",
      "log_step: 0 slot: 2 self.activation_results['slots_won'] = \n",
      "log_step: 0 slot: 2\n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \tNone \n",
      "slot won: \tNone \n",
      "slot won: \tNone\n",
      "log_step: 0 slot: 2      agents bid_size = \n",
      "log_step: 0 slot: 2\n",
      "size: \t66 \n",
      "size: \t103 \n",
      "size: \t28 \n",
      "size: \t72 \n",
      "size: \t82 \n",
      "size: \t87\n",
      "log_step: 0 slot: 2 self.activation_results['slot_settlement_prices_DE'] = \n",
      "log_step: 0 slot: 2\n",
      "price: \t16.67 \n",
      "price: \t19.06 \n",
      "price: \t17.72 \n",
      "price: \tNone \n",
      "price: \tNone \n",
      "price: \tNone\n",
      "log_step: 0 slot: 3 Current Slot Time: (D) = 2020-07-03 10:00:00+00:00\n",
      "log_step: 0 slot: 3 agents_bid_size = 72\n",
      "log_step: 0 slot: 3 agents_bid_price = 3202.5955\n",
      "log_step: 0 slot: 3 settlement_price_DE : 16.67\n",
      "log_step: 0 slot: 3 self.activation_results['slots_won'] = \n",
      "log_step: 0 slot: 3\n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \tNone \n",
      "slot won: \tNone\n",
      "log_step: 0 slot: 3      agents bid_size = \n",
      "log_step: 0 slot: 3\n",
      "size: \t66 \n",
      "size: \t103 \n",
      "size: \t28 \n",
      "size: \t72 \n",
      "size: \t82 \n",
      "size: \t87\n",
      "log_step: 0 slot: 3 self.activation_results['slot_settlement_prices_DE'] = \n",
      "log_step: 0 slot: 3\n",
      "price: \t16.67 \n",
      "price: \t19.06 \n",
      "price: \t17.72 \n",
      "price: \t16.67 \n",
      "price: \tNone \n",
      "price: \tNone\n",
      "log_step: 0 slot: 4 Current Slot Time: (D) = 2020-07-03 14:00:00+00:00\n",
      "log_step: 0 slot: 4 agents_bid_size = 82\n",
      "log_step: 0 slot: 4 agents_bid_price = 675.51514\n",
      "log_step: 0 slot: 4 settlement_price_DE : 18.0\n",
      "log_step: 0 slot: 4 self.activation_results['slots_won'] = \n",
      "log_step: 0 slot: 4\n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \tNone\n",
      "log_step: 0 slot: 4      agents bid_size = \n",
      "log_step: 0 slot: 4\n",
      "size: \t66 \n",
      "size: \t103 \n",
      "size: \t28 \n",
      "size: \t72 \n",
      "size: \t82 \n",
      "size: \t87\n",
      "log_step: 0 slot: 4 self.activation_results['slot_settlement_prices_DE'] = \n",
      "log_step: 0 slot: 4\n",
      "price: \t16.67 \n",
      "price: \t19.06 \n",
      "price: \t17.72 \n",
      "price: \t16.67 \n",
      "price: \t18.0 \n",
      "price: \tNone\n",
      "log_step: 0 slot: 5 Current Slot Time: (D) = 2020-07-03 18:00:00+00:00\n",
      "log_step: 0 slot: 5 agents_bid_size = 87\n",
      "log_step: 0 slot: 5 agents_bid_price = 1285.9987\n",
      "log_step: 0 slot: 5 settlement_price_DE : 16.67\n",
      "log_step: 0 slot: 5 self.activation_results['slots_won'] = \n",
      "log_step: 0 slot: 5\n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1 \n",
      "slot won: \t-1\n",
      "log_step: 0 slot: 5      agents bid_size = \n",
      "log_step: 0 slot: 5\n",
      "size: \t66 \n",
      "size: \t103 \n",
      "size: \t28 \n",
      "size: \t72 \n",
      "size: \t82 \n",
      "size: \t87\n",
      "log_step: 0 slot: 5 self.activation_results['slot_settlement_prices_DE'] = \n",
      "log_step: 0 slot: 5\n",
      "price: \t16.67 \n",
      "price: \t19.06 \n",
      "price: \t17.72 \n",
      "price: \t16.67 \n",
      "price: \t18.0 \n",
      "price: \t16.67\n",
      "log_step: 0 slot: None Reward Overview:\n",
      "log_step: 0 slot: None self.activation_results['slots_won']: [-1, -1, -1, -1, -1, -1]\n",
      "log_step: 0 slot: None len(self.activation_results['slots_won']) : 6\n",
      "log_step: 0 slot: 0 slot no. 0\n",
      "log_step: 0 slot: 0 slot no 0 was lost\n",
      "log_step: 0 slot: 0 distance_to_settlement_price = 2276.382978515625\n",
      "log_step: 0 slot: 0 auction_reward = 0.2215086072340895\n",
      "log_step: 0 slot: 0 for slot no : 0\n",
      "log_step: 0 slot: 0 self.activation_results['slot_settlement_prices_DE'][slot]: 16.67\n",
      "log_step: 0 slot: 0 auction_reward: 0.2215086072340895\n",
      "log_step: 0 slot: 0 reservation_reward: 0\n",
      "log_step: 0 slot: 0 activation_reward: 0\n",
      "log_step: 0 slot: 0 slot_reward: 0.2215086072340895\n",
      "log_step: 0 slot: 0 weighted_slot_reward (slot_reward/3) = 0.07383620241136317\n",
      "log_step: 0 slot: 0 slot_profit: 0\n",
      "log_step: 0 slot: 1 slot no. 1\n",
      "log_step: 0 slot: 1 slot no 1 was lost\n",
      "log_step: 0 slot: 1 distance_to_settlement_price = 1455.79595703125\n",
      "log_step: 0 slot: 1 auction_reward = 0.34897766712164346\n",
      "log_step: 0 slot: 1 for slot no : 1\n",
      "log_step: 0 slot: 1 self.activation_results['slot_settlement_prices_DE'][slot]: 19.06\n",
      "log_step: 0 slot: 1 auction_reward: 0.34897766712164346\n",
      "log_step: 0 slot: 1 reservation_reward: 0\n",
      "log_step: 0 slot: 1 activation_reward: 0\n",
      "log_step: 0 slot: 1 slot_reward: 0.34897766712164346\n",
      "log_step: 0 slot: 1 weighted_slot_reward (slot_reward/3) = 0.11632588904054782\n",
      "log_step: 0 slot: 1 slot_profit: 0\n",
      "log_step: 0 slot: 2 slot no. 2\n",
      "log_step: 0 slot: 2 slot no 2 was lost\n",
      "log_step: 0 slot: 2 distance_to_settlement_price = 983.6936352539062\n",
      "log_step: 0 slot: 2 auction_reward = 0.44345584247612635\n",
      "log_step: 0 slot: 2 for slot no : 2\n",
      "log_step: 0 slot: 2 self.activation_results['slot_settlement_prices_DE'][slot]: 17.72\n",
      "log_step: 0 slot: 2 auction_reward: 0.44345584247612635\n",
      "log_step: 0 slot: 2 reservation_reward: 0\n",
      "log_step: 0 slot: 2 activation_reward: 0\n",
      "log_step: 0 slot: 2 slot_reward: 0.44345584247612635\n",
      "log_step: 0 slot: 2 weighted_slot_reward (slot_reward/3) = 0.14781861415870878\n",
      "log_step: 0 slot: 2 slot_profit: 0\n",
      "log_step: 0 slot: 3 slot no. 3\n",
      "log_step: 0 slot: 3 slot no 3 was lost\n",
      "log_step: 0 slot: 3 distance_to_settlement_price = 3185.925458984375\n",
      "log_step: 0 slot: 3 auction_reward = 0.10946718439813041\n",
      "log_step: 0 slot: 3 for slot no : 3\n",
      "log_step: 0 slot: 3 self.activation_results['slot_settlement_prices_DE'][slot]: 16.67\n",
      "log_step: 0 slot: 3 auction_reward: 0.10946718439813041\n",
      "log_step: 0 slot: 3 reservation_reward: 0\n",
      "log_step: 0 slot: 3 activation_reward: 0\n",
      "log_step: 0 slot: 3 slot_reward: 0.10946718439813041\n",
      "log_step: 0 slot: 3 weighted_slot_reward (slot_reward/3) = 0.03648906146604347\n",
      "log_step: 0 slot: 3 slot_profit: 0\n",
      "log_step: 0 slot: 4 slot no. 4\n",
      "log_step: 0 slot: 4 slot no 4 was lost\n",
      "log_step: 0 slot: 4 distance_to_settlement_price = 657.51513671875\n",
      "log_step: 0 slot: 4 auction_reward = 0.5262840741570078\n",
      "log_step: 0 slot: 4 for slot no : 4\n",
      "log_step: 0 slot: 4 self.activation_results['slot_settlement_prices_DE'][slot]: 18.0\n",
      "log_step: 0 slot: 4 auction_reward: 0.5262840741570078\n",
      "log_step: 0 slot: 4 reservation_reward: 0\n",
      "log_step: 0 slot: 4 activation_reward: 0\n",
      "log_step: 0 slot: 4 slot_reward: 0.5262840741570078\n",
      "log_step: 0 slot: 4 weighted_slot_reward (slot_reward/3) = 0.17542802471900262\n",
      "log_step: 0 slot: 4 slot_profit: 0\n",
      "log_step: 0 slot: 5 slot no. 5\n",
      "log_step: 0 slot: 5 slot no 5 was lost\n",
      "log_step: 0 slot: 5 distance_to_settlement_price = 1269.3286572265624\n",
      "log_step: 0 slot: 5 auction_reward = 0.3837097210288828\n",
      "log_step: 0 slot: 5 for slot no : 5\n",
      "log_step: 0 slot: 5 self.activation_results['slot_settlement_prices_DE'][slot]: 16.67\n",
      "log_step: 0 slot: 5 auction_reward: 0.3837097210288828\n",
      "log_step: 0 slot: 5 reservation_reward: 0\n",
      "log_step: 0 slot: 5 activation_reward: 0\n",
      "log_step: 0 slot: 5 slot_reward: 0.3837097210288828\n",
      "log_step: 0 slot: 5 weighted_slot_reward (slot_reward/3) = 0.12790324034296094\n",
      "log_step: 0 slot: 5 slot_profit: 0\n",
      "log_step: 0 day_reward (sum of all weighted_slot_reward ) = 0.6778010321386269\n",
      "log_step: 0 weighted_day_reward (= day_reward / 6) for all 6 slots : 0.11296683868977114\n",
      "log_step: 0 day_revenue (sum of all slot_revenue) = 0.0\n",
      "log_step: 0 day_penalties (sum of all slot_penalty) = 0.0\n",
      "log_step: 0 day_profit (sum of all slot_profit) = 0.0\n"
     ]
    }
   ],
   "source": [
    "# It will check your custom environment and output additional warnings if needed\n",
    "env_to_check = make('VPPBiddingEnv-TEST-v1', render_mode=None)\n",
    "check_env(env_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b9778-4b51-48b3-9b93-8fee865a49ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stable Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff546b2-3a85-4377-bc6d-75d3d60b41aa",
   "metadata": {},
   "source": [
    "### Offline Training and later sync logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5787c994-9554-4c38-94df-ee1adafe2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"0cea1eee5f42654eca0de365f0acca116367c9b4\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc579db-a0a3-474c-bc1b-d139ac256d18",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1fcf70-09cd-497e-9d99-f04cbe27ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_algo(algo): \n",
    "    env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "    env = Monitor(env) \n",
    "    env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "    \n",
    "    if algo == \"R_PPO\": \n",
    "        policy = 'MultiInputLstmPolicy'\n",
    "    else: \n",
    "        policy = 'MultiInputPolicy'\n",
    "\n",
    "    wandb.init(\n",
    "        sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "        project=\"RL-VPP-Training\",\n",
    "        monitor_gym=True,       # automatically upload gym environements' videos\n",
    "        save_code=True,\n",
    "        entity=\"jlu237\", \n",
    "        tags=[algo] + EXPERIMENT_TAGS, \n",
    "        job_type=\"training\"\n",
    "    )\n",
    "    \n",
    "    model_params = HYPERPARAMS[algo]\n",
    "    \n",
    "\n",
    "    \n",
    "    model = ALGOS[algo](policy, env, verbose=0,  seed = 1, **model_params)\n",
    "\n",
    "    model.learn(total_timesteps=EXPERIMENT_TIMESTEPS,\n",
    "                log_interval=1,\n",
    "                progress_bar = True,\n",
    "                callback=WandbCallback(\n",
    "                    gradient_save_freq=1,\n",
    "                    verbose=0))\n",
    "    wandb.finish()\n",
    "    return_code = subprocess.run(\"wandb sync wandb/latest-run\", shell=True)\n",
    "    \n",
    "    return return_code, model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b85f6d-5c58-48e7-a799-cebc8f392eca",
   "metadata": {},
   "source": [
    "## Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3282c7-e8c2-4a16-a327-c6e3a7da08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algo(algo, model):\n",
    "    eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "    eval_env = Monitor(eval_env) \n",
    "    eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "    wandb.init(\n",
    "        sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "        project=\"RL-VPP-Evaluation\",\n",
    "        save_code=True,\n",
    "        entity=\"jlu237\", \n",
    "        tags=[algo] + EXPERIMENT_TAGS, \n",
    "        job_type=\"eval\",\n",
    "    )\n",
    "\n",
    "    episodes = 140\n",
    "    for i_episode in range(episodes):\n",
    "        observation = eval_env.reset()\n",
    "        if algo == \"R_PPO\":\n",
    "            lstm_states = None\n",
    "            num_envs = 1\n",
    "            # Episode start signals are used to reset the lstm states\n",
    "            episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "            for t in range(1):\n",
    "                action, lstm_states = model.predict(observation, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "                observation, reward, dones, info = eval_env.step(action)\n",
    "                episode_starts = dones\n",
    "        else: \n",
    "            for t in range(1):\n",
    "                action, _states = model.predict(observation, deterministic = True)\n",
    "                observation, reward, done, info = eval_env.step(action)\n",
    "\n",
    "    eval_env.close()\n",
    "    wandb.finish()\n",
    "    return_code = subprocess.run(\"wandb sync wandb/latest-run\", shell=True)\n",
    "    return return_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a2665c9-7951-4d7b-8db6-63d6a0b2d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "#  NormalActionNoise(mean=[0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.],\n",
    "#                                              sigma=[0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106]\n",
    "#                                             )\n",
    "\n",
    "HYPERPARAMS = {\n",
    "    \n",
    "    \"A2C\": {},\n",
    "    \n",
    "    \"DDPG\": {},\n",
    "    \n",
    "    \"SAC\": {'learning_rate': 0.010591885782399316,\n",
    "            'batch_size': 100,\n",
    "            'buffer_size': 100000,\n",
    "            'learning_starts': 10, \n",
    "            'train_freq': 16,\n",
    "            'gradient_steps': 2,\n",
    "            'ent_coef': 0.05,\n",
    "            'tau': 0.005,\n",
    "            'gamma': 0.98,\n",
    "            'policy_kwargs': {\n",
    "                'net_arch': [256, 256],\n",
    "                'activation_fn': nn.Tanh,\n",
    "                'log_std_init': -3.4586660996768894,\n",
    "                'use_sde': False},\n",
    "            'sde_sample_freq': 0,\n",
    "            'target_entropy': -10,\n",
    "            'action_noise': NormalActionNoise(mean=[0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.],\n",
    "                                              sigma=[0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106]\n",
    "                                             )\n",
    "           },\n",
    "    \n",
    "    \"PPO\": {},\n",
    "    \n",
    "    \"TD3\": {},\n",
    "    \n",
    "    #\"DQN\": {},\n",
    "    \n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": {},\n",
    "    \n",
    "    \"TRPO\": {},\n",
    "    \n",
    "    \"R_PPO\": {'learning_rate': linear_schedule(0.00047746791329352097),\n",
    "              'n_steps': 8,\n",
    "              'batch_size': 8,\n",
    "              'n_epochs': 10,\n",
    "              'gamma': 0.98,\n",
    "              'gae_lambda': 0.9,\n",
    "              'clip_range': 0.4,\n",
    "              'normalize_advantage': True,\n",
    "              'ent_coef': 0.03476154346691902,\n",
    "              'vf_coef': 0.6589086411755256,\n",
    "              'max_grad_norm': 5,\n",
    "              'target_kl': 0.1,\n",
    "              'policy_kwargs': {\n",
    "                  'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}],\n",
    "                  'full_std': True,\n",
    "                  'activation_fn': nn.Tanh,\n",
    "                  'ortho_init': True,\n",
    "                  'log_std_init': -2.303063874869516},\n",
    "              'sde_sample_freq': -1},\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc088d8b-c4fe-42a0-b2a5-ab31fa51c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGOS = {\n",
    "    \"A2C\": A2C,\n",
    "    \"DDPG\": DDPG,\n",
    "    \"PPO\": PPO,\n",
    "    \"SAC\": SAC,\n",
    "    \"TD3\": TD3,\n",
    "    #\"DQN\": DQN,\n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": TQC,\n",
    "    \"TRPO\": TRPO,\n",
    "    \"R_PPO\": RecurrentPPO,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f4386e0-1c92-4777-b298-3e1e35b01648",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_TAGS = [\"new_metrics\", \"new_pipeline\"]\n",
    "EXPERIMENT_TIMESTEPS = 2785  #2785 =  557 * 5 cycles of summer 2022 - summer 2022, 10 cycles = 5570"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b29c-4008-4b4a-9405-679982f2bb93",
   "metadata": {},
   "source": [
    "## Train all Algorithms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f12653bf-0f0f-4ce5-bb6a-dfc9b0fc7e29",
   "metadata": {},
   "source": [
    "algo_list = [\"SAC\", \"DDPG\", \"TD3\", \"TRPO\", \"R_PPO\",\"A2C\", \"PPO\", \"TQC\"]\n",
    "\n",
    "for algo in algo_list:\n",
    "    try:\n",
    "        print(\"now training \" + algo)\n",
    "        return_code, model = train_algo(algo) \n",
    "        print(\"training finished with : \" + str(return_code))\n",
    "        return_code = evaluate_algo(algo, model)\n",
    "        print(\"evaluation finished with : \" + str(return_code))        \n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc34a3c-438e-4efb-ac7a-653482b1affe",
   "metadata": {},
   "source": [
    "## Single Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f527affb-3f04-4963-94eb-2d0d0f581241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training R_PPO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e5f475e6dd447e8e005d604bfea3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>step_activ_count</td><td>▁▁▁▁▁▁▁▁▁▁▅▂▂▂▇▄▄▄▇▇▄█▇█▇██▂▇▄██▅███▅██▁</td></tr><tr><td>step_activ_ratio</td><td>▁▁▁▁▁▁▁▁▁▁▅▃▅▅▇▆▆▆▇▇▆▇▇▇▇▇▇▅▇▆▇▇▆█▇▇██▇▁</td></tr><tr><td>step_lost_count</td><td>██████▇█▅▅▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁</td></tr><tr><td>step_not_activ_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_not_part_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁██▁█</td></tr><tr><td>step_not_res_count</td><td>▁▁▁▁▁▁▂▁▅▅▁▅▇▅▂▅▅▄▂▂▅▁▂▁▂▁▁▇▂▅▁▁▄▁▁▁▄▁▁█</td></tr><tr><td>step_penalties</td><td>██████▅█▆▆█▅▃▁▇▅▇▇██▆██████▅████████▇██▆</td></tr><tr><td>step_profit</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▃▁▁▁▃▁▅▂█▂▂▂▁▂▂▇▄▁▃▂▂▂▂▅▁</td></tr><tr><td>step_res_count</td><td>▁▁▁▁▁▁▁▁▁▁▅▂▂▂▇▄▄▄▇▇▄█▇█▇██▂▇▄██▅███▅██▁</td></tr><tr><td>step_res_ratio</td><td>▁▁▁▁▁▁▁▁▁▁▅▂▂▂▆▃▃▄▆▆▃▇▆▇▆▇▇▂▆▃▇▇▅█▇▇▅█▇▁</td></tr><tr><td>step_revenue</td><td>▁▁▁▁▁▁▂▁▃▄▂▆▅█▃▆▂▂▂▄▄▅▄█▂▂▂▆▃▃▇▄▂▃▂▂▃▂▅▂</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▂▂▁▃▃▆▅▅▄▇▆▆▅▇▇▆█▇█▇██▅▇▆██▇███▇██▅</td></tr><tr><td>step_won_count</td><td>▁▁▁▁▁▁▂▁▅▅▅▇█▇███▇██████████████████████</td></tr><tr><td>step_won_ratio</td><td>▁▁▁▁▁▁▂▁▅▅▅▇█▇███▇██████████████████████</td></tr><tr><td>total_activ_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>total_not_activ_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_not_part_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▅▅▆▆▇█</td></tr><tr><td>total_not_res_count</td><td>▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>total_penalties</td><td>████████▇▆▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_profit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇██</td></tr><tr><td>total_res_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>total_revenue</td><td>▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>total_reward</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>total_won_count</td><td>▁▁▂▂▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2791</td></tr><tr><td>step_activ_count</td><td>5</td></tr><tr><td>step_activ_ratio</td><td>0.83333</td></tr><tr><td>step_lost_count</td><td>1</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>0</td></tr><tr><td>step_not_res_count</td><td>0</td></tr><tr><td>step_penalties</td><td>0.0</td></tr><tr><td>step_profit</td><td>783.04</td></tr><tr><td>step_res_count</td><td>5</td></tr><tr><td>step_res_ratio</td><td>0.83333</td></tr><tr><td>step_revenue</td><td>783.04</td></tr><tr><td>step_reward</td><td>0.85633</td></tr><tr><td>step_won_count</td><td>5</td></tr><tr><td>step_won_ratio</td><td>0.83333</td></tr><tr><td>total_activ_count</td><td>7090</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>612</td></tr><tr><td>total_not_res_count</td><td>3462</td></tr><tr><td>total_penalties</td><td>-33307034.09734</td></tr><tr><td>total_profit</td><td>7925874.23253</td></tr><tr><td>total_res_count</td><td>7090</td></tr><tr><td>total_revenue</td><td>14642825.29</td></tr><tr><td>total_reward</td><td>1601.06313</td></tr><tr><td>total_won_count</td><td>5588</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221124_180001-39lyp9dz<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221124_180001-39lyp9dz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-VPP-Training/runs/39lyp9dz ... done.\n",
      "training finished with : CompletedProcess(args='wandb sync wandb/latest-run', returncode=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>step_activ_count</td><td>▁▁██▄▁▁▇██████████████▇███▁▁██▄▁▁▇██████</td></tr><tr><td>step_activ_ratio</td><td>▁▁███▁▁████▇███▇██▇███████▁▁███▁▁████▇██</td></tr><tr><td>step_lost_count</td><td>▁▁▁▁▁▁▁▁▁▁▁█▁▁▁█▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁</td></tr><tr><td>step_not_activ_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_not_part_count</td><td>███████████▁███▁██▁██████████████████▁██</td></tr><tr><td>step_not_res_count</td><td>██▁▁▅██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁██▁▁▅██▂▁▁▁▁▁▁</td></tr><tr><td>step_penalties</td><td>▆▅██▇▆▇███████████████████▂▄██▆▁▆███████</td></tr><tr><td>step_profit</td><td>▁▁▃▃▂▁▂▄▂▃▃▃▂▂▂▃▂▃▄▆▇▆▄▅▅▅▁▁▆▆▄▁▄█▇▇▄█▅▄</td></tr><tr><td>step_res_count</td><td>▁▁██▄▁▁▇██████████████▇███▁▁██▄▁▁▇██████</td></tr><tr><td>step_res_ratio</td><td>▁▁██▄▁▁▇███▇███▇██▇███▇███▁▁██▄▁▁▇███▇██</td></tr><tr><td>step_revenue</td><td>▁▁▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▂▂▄▅▅▃▄▃▃▃▄▄▄▅▇█▆▅▅▂▆▃▃</td></tr><tr><td>step_reward</td><td>▁▁██▄▁▂▇█▇██████▇▇████▇███▁▁██▄▁▂▇█▇████</td></tr><tr><td>step_won_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_won_ratio</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_activ_count</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>total_not_activ_count</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_not_part_count</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>total_not_res_count</td><td>▁▁▂▂▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▆▆▆▆▇████████</td></tr><tr><td>total_penalties</td><td>██▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▄▄▄▃▂▁▁▁▁▁▁▁▁</td></tr><tr><td>total_profit</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▇▇▇██</td></tr><tr><td>total_res_count</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>total_revenue</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▇▇▇███</td></tr><tr><td>total_reward</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>total_won_count</td><td>▁▁▁▁▁▁▁▁▁▂▂▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>139</td></tr><tr><td>step_activ_count</td><td>5</td></tr><tr><td>step_activ_ratio</td><td>1.0</td></tr><tr><td>step_lost_count</td><td>0</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>1</td></tr><tr><td>step_not_res_count</td><td>0</td></tr><tr><td>step_penalties</td><td>0.0</td></tr><tr><td>step_profit</td><td>2956.64</td></tr><tr><td>step_res_count</td><td>5</td></tr><tr><td>step_res_ratio</td><td>1.0</td></tr><tr><td>step_revenue</td><td>2956.64</td></tr><tr><td>step_reward</td><td>0.8522</td></tr><tr><td>step_won_count</td><td>5</td></tr><tr><td>step_won_ratio</td><td>0.83333</td></tr><tr><td>total_activ_count</td><td>548</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>120</td></tr><tr><td>total_not_res_count</td><td>152</td></tr><tr><td>total_penalties</td><td>-426816.3952</td></tr><tr><td>total_profit</td><td>403414.24515</td></tr><tr><td>total_res_count</td><td>548</td></tr><tr><td>total_revenue</td><td>510175.28</td></tr><tr><td>total_reward</td><td>109.021</td></tr><tr><td>total_won_count</td><td>20</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221124_182317-2al7ob4o<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221124_182317-2al7ob4o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-VPP-Evaluation/runs/2al7ob4o ... done.\n",
      "evaluation finished with : CompletedProcess(args='wandb sync wandb/latest-run', returncode=0)\n"
     ]
    }
   ],
   "source": [
    "ALGORITHM = \"R_PPO\"\n",
    "\n",
    "try:\n",
    "    print(\"now training \" + ALGORITHM)\n",
    "    return_code, model = train_algo(ALGORITHM) \n",
    "    print(\"training finished with : \" + str(return_code))\n",
    "    return_code = evaluate_algo(ALGORITHM, model)\n",
    "    print(\"evaluation finished with : \" + str(return_code))\n",
    "except AssertionError as e:\n",
    "    # Sometimes, random hyperparams can generate NaN\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f8e0e-a384-41a7-8188-1f6705d0f72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
