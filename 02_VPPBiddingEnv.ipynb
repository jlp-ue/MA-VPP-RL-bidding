{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a32f4a0-96ea-48fe-a8ac-fa6adbef7f3e",
   "metadata": {},
   "source": [
    "# Run Agent in Environment with different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37105a1-c06c-445d-b9f9-afc70b8764e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jan-Lukas.Pflaum/.virtualenvs/thesis/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "# Basics\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Data \n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import numpy as np\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "from gym import make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db6c67-ec11-492b-b29d-773764e7dc09",
   "metadata": {},
   "source": [
    "## Register the Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de7d899-f638-44cf-8c5b-3f80b0723019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register\n",
    "   \n",
    "register(\n",
    "    id=\"VPPBiddingEnv-TRAIN-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"DEBUG\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"training\",\n",
    "           }\n",
    ")\n",
    "\n",
    "'''register(\n",
    "    id=\"VPPBiddingGoalEnv-TRAIN-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_GoalEnv:VPPBiddingGoalEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"DEBUG\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"training\",\n",
    "           }\n",
    ")'''\n",
    "\n",
    "register(\n",
    "    id=\"VPPBiddingEnv-EVAL-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"DEBUG\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"eval\",\n",
    "           }\n",
    ")\n",
    "\n",
    "register(\n",
    "    id=\"VPPBiddingEnv-TEST-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"INFO\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"test\",\n",
    "           }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17256e7-0240-435d-a641-55d444a43406",
   "metadata": {},
   "source": [
    "## Test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72671bc0-33dd-4453-81b9-d86c8979a5ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log level = info\n",
      "log level = warning\n",
      "Bid Submission time (D-1) = 2020-07-02 05:00:00+00:00\n",
      "Gate Closure time (D-1) = 2020-07-02 06:00:00+00:00\n",
      "Historic Data Window: from 2020-07-01 05:00:00+00:00 to 2020-07-02 04:45:00+00:00 \n",
      "Forecast Data Window: from 2020-07-02 22:00:00+00:00 to 2020-07-03 21:45:00+00:00 \n",
      "Current Slot Time: (D) = 2020-07-02 22:00:00+00:00\n",
      "agents_bid_size = 41\n",
      "agents_bid_price = 2943.582\n",
      "settlement_price_DE : 16.67\n",
      "self.activation_results['slots_won'] = \n",
      "slot won: \t0\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "     agents bid_size = \n",
      "size: \t41\n",
      "size: \t53\n",
      "size: \t3\n",
      "size: \t59\n",
      "size: \t15\n",
      "size: \t6\n",
      "self.activation_results['slot_settlement_prices_DE'] = \n",
      "price: \t16.67\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "Current Slot Time: (D) = 2020-07-03 02:00:00+00:00\n",
      "agents_bid_size = 53\n",
      "agents_bid_price = 3190.0366\n",
      "settlement_price_DE : 19.06\n",
      "self.activation_results['slots_won'] = \n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "     agents bid_size = \n",
      "size: \t41\n",
      "size: \t53\n",
      "size: \t3\n",
      "size: \t59\n",
      "size: \t15\n",
      "size: \t6\n",
      "self.activation_results['slot_settlement_prices_DE'] = \n",
      "price: \t16.67\n",
      "price: \t19.06\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "Current Slot Time: (D) = 2020-07-03 06:00:00+00:00\n",
      "agents_bid_size = 3\n",
      "agents_bid_price = 3450.3914\n",
      "settlement_price_DE : 17.72\n",
      "self.activation_results['slots_won'] = \n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "     agents bid_size = \n",
      "size: \t41\n",
      "size: \t53\n",
      "size: \t3\n",
      "size: \t59\n",
      "size: \t15\n",
      "size: \t6\n",
      "self.activation_results['slot_settlement_prices_DE'] = \n",
      "price: \t16.67\n",
      "price: \t19.06\n",
      "price: \t17.72\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "Current Slot Time: (D) = 2020-07-03 10:00:00+00:00\n",
      "agents_bid_size = 59\n",
      "agents_bid_price = 1073.1039\n",
      "settlement_price_DE : 16.67\n",
      "self.activation_results['slots_won'] = \n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \tNone\n",
      "slot won: \tNone\n",
      "     agents bid_size = \n",
      "size: \t41\n",
      "size: \t53\n",
      "size: \t3\n",
      "size: \t59\n",
      "size: \t15\n",
      "size: \t6\n",
      "self.activation_results['slot_settlement_prices_DE'] = \n",
      "price: \t16.67\n",
      "price: \t19.06\n",
      "price: \t17.72\n",
      "price: \t16.67\n",
      "price: \t0.0\n",
      "price: \t0.0\n",
      "Current Slot Time: (D) = 2020-07-03 14:00:00+00:00\n",
      "agents_bid_size = 15\n",
      "agents_bid_price = 2215.4607\n",
      "settlement_price_DE : 18.0\n",
      "self.activation_results['slots_won'] = \n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \tNone\n",
      "     agents bid_size = \n",
      "size: \t41\n",
      "size: \t53\n",
      "size: \t3\n",
      "size: \t59\n",
      "size: \t15\n",
      "size: \t6\n",
      "self.activation_results['slot_settlement_prices_DE'] = \n",
      "price: \t16.67\n",
      "price: \t19.06\n",
      "price: \t17.72\n",
      "price: \t16.67\n",
      "price: \t18.0\n",
      "price: \t0.0\n",
      "Current Slot Time: (D) = 2020-07-03 18:00:00+00:00\n",
      "agents_bid_size = 6\n",
      "agents_bid_price = 759.04865\n",
      "settlement_price_DE : 16.67\n",
      "self.activation_results['slots_won'] = \n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "slot won: \t0\n",
      "     agents bid_size = \n",
      "size: \t41\n",
      "size: \t53\n",
      "size: \t3\n",
      "size: \t59\n",
      "size: \t15\n",
      "size: \t6\n",
      "self.activation_results['slot_settlement_prices_DE'] = \n",
      "price: \t16.67\n",
      "price: \t19.06\n",
      "price: \t17.72\n",
      "price: \t16.67\n",
      "price: \t18.0\n",
      "price: \t16.67\n",
      "Reward Overview:\n",
      "total step_reward for all 6 slots : -6000\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "env_to_check = make('VPPBiddingEnv-TEST-v1', render_mode=None)\n",
    "check_env(env_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b9778-4b51-48b3-9b93-8fee865a49ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stable Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f4386e0-1c92-4777-b298-3e1e35b01648",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_tags = [\"delivery possible +10k\"]\n",
    "experiment_timesteps = 2785  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff546b2-3a85-4377-bc6d-75d3d60b41aa",
   "metadata": {},
   "source": [
    "### Offline Training and later sync logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5787c994-9554-4c38-94df-ee1adafe2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"0cea1eee5f42654eca0de365f0acca116367c9b4\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf65e36-b792-4eee-9dd3-5ddcae5b91cb",
   "metadata": {},
   "source": [
    "## SAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdce13-d9e6-49c4-8405-241856fbe544",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a05d95-6c52-4826-9484-bcc9e8306ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jan-Lukas.Pflaum/.virtualenvs/thesis/lib/python3.8/site-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "/Users/Jan-Lukas.Pflaum/.virtualenvs/thesis/lib/python3.8/site-packages/wandb/sdk/lib/ipython.py:47: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jan-Lukas.Pflaum/.virtualenvs/thesis/lib/python3.8/site-packages/nbformat/validator.py:315: DeprecationWarning:\n",
      "\n",
      "Passing a schema to Validator.iter_errors is deprecated and will be removed in a future release. Call validator.evolve(schema=new_schema).iter_errors(...) instead.\n",
      "\n",
      "/Users/Jan-Lukas.Pflaum/.virtualenvs/thesis/lib/python3.8/site-packages/wandb/sdk/lib/ipython.py:47: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>step_profit</td><td>▇▇▇▇▇▇██▇▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>step_reward</td><td>▁▁▁▁▃▃▄▃▁▃▁██████▃▁▁▆█▃█▃█▆▃▃▃▃▃▁▃▃▃▁█▆▁</td></tr><tr><td>total_profit</td><td>█████▇▆▂▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅</td></tr><tr><td>total_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2784</td></tr><tr><td>step_profit</td><td>0</td></tr><tr><td>step_reward</td><td>-6000</td></tr><tr><td>total_profit</td><td>-299916.571</td></tr><tr><td>total_reward</td><td>86003846.70046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20220826_114525-wa1sm81m<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20220826_114525-wa1sm81m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=None)\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"SAC\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = SAC(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb29214f-d5c9-4a8e-9bd1-ce2fb5bfc118",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-VPP-Training/runs/wa1sm81m ... done.\n"
     ]
    }
   ],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22814aa5-3352-4191-be75-438089e4c506",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33bbc69a-b0b1-436c-afbb-3d4016a8b197",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jan-Lukas.Pflaum/.virtualenvs/thesis/lib/python3.8/site-packages/wandb/sdk/lib/ipython.py:47: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Info: {'bid_submission_time': '2020-08-02 05:00:00+00:00', 'step_reward': 25036.6, 'step_profit': 18.3, 'total_reward': 25036.6, 'total_profit': 18.3, 'TimeLimit.truncated': False, 'episode': {'r': 25036.6, 'l': 1, 't': 1.282693}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step cannot be set when using syncing with tensorboard. Please log your step values as a metric such as 'global_step'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Info: {'bid_submission_time': '2020-08-03 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 19036.6, 'total_profit': 18.3, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 1.615249}}\n",
      "Episode: 2 Info: {'bid_submission_time': '2020-08-04 05:00:00+00:00', 'step_reward': 15053.15, 'step_profit': 26.58, 'total_reward': 34089.75, 'total_profit': 44.88, 'TimeLimit.truncated': False, 'episode': {'r': 15053.152, 'l': 1, 't': 1.869131}}\n",
      "Episode: 3 Info: {'bid_submission_time': '2020-08-05 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 28089.75, 'total_profit': 44.88, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 2.086511}}\n",
      "Episode: 4 Info: {'bid_submission_time': '2020-08-06 05:00:00+00:00', 'step_reward': 36071.59, 'step_profit': 28.84, 'total_reward': 64161.34, 'total_profit': 87.62, 'TimeLimit.truncated': False, 'episode': {'r': 36071.586, 'l': 1, 't': 2.353317}}\n",
      "Episode: 5 Info: {'bid_submission_time': '2020-08-07 05:00:00+00:00', 'step_reward': 15030.0, 'step_profit': 15.0, 'total_reward': 79191.34, 'total_profit': 102.62, 'TimeLimit.truncated': False, 'episode': {'r': 15030.003, 'l': 1, 't': 2.631417}}\n",
      "Episode: 6 Info: {'bid_submission_time': '2020-08-08 05:00:00+00:00', 'step_reward': 25061.24, 'step_profit': 30.62, 'total_reward': 104252.58, 'total_profit': 133.24, 'TimeLimit.truncated': False, 'episode': {'r': 25061.24, 'l': 1, 't': 2.899393}}\n",
      "Episode: 7 Info: {'bid_submission_time': '2020-08-30 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 98252.58, 'total_profit': 133.24, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 3.218414}}\n",
      "Episode: 8 Info: {'bid_submission_time': '2020-08-31 05:00:00+00:00', 'step_reward': 56181.42, 'step_profit': 72.66, 'total_reward': 154434.0, 'total_profit': 242.0, 'TimeLimit.truncated': False, 'episode': {'r': 56181.42, 'l': 1, 't': 3.481383}}\n",
      "Episode: 9 Info: {'bid_submission_time': '2020-09-01 05:00:00+00:00', 'step_reward': 25092.16, 'step_profit': 46.08, 'total_reward': 179526.16, 'total_profit': 288.08, 'TimeLimit.truncated': False, 'episode': {'r': 25092.16, 'l': 1, 't': 3.731487}}\n",
      "Episode: 10 Info: {'bid_submission_time': '2020-09-02 05:00:00+00:00', 'step_reward': 25073.84, 'step_profit': 36.92, 'total_reward': 204600.0, 'total_profit': 325.0, 'TimeLimit.truncated': False, 'episode': {'r': 25073.84, 'l': 1, 't': 4.005843}}\n",
      "Episode: 11 Info: {'bid_submission_time': '2020-09-03 05:00:00+00:00', 'step_reward': 56190.6, 'step_profit': 74.3, 'total_reward': 260790.6, 'total_profit': 441.3, 'TimeLimit.truncated': False, 'episode': {'r': 56190.6, 'l': 1, 't': 4.242031}}\n",
      "Episode: 12 Info: {'bid_submission_time': '2020-09-04 05:00:00+00:00', 'step_reward': 56151.36, 'step_profit': 61.48, 'total_reward': 316941.96, 'total_profit': 531.18, 'TimeLimit.truncated': False, 'episode': {'r': 56151.36, 'l': 1, 't': 4.500047}}\n",
      "Episode: 13 Info: {'bid_submission_time': '2020-09-05 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 310941.96, 'total_profit': 531.18, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 4.75069}}\n",
      "Episode: 14 Info: {'bid_submission_time': '2020-09-27 05:00:00+00:00', 'step_reward': 25084.9, 'step_profit': 42.45, 'total_reward': 336026.86, 'total_profit': 573.63, 'TimeLimit.truncated': False, 'episode': {'r': 25084.9, 'l': 1, 't': 4.991929}}\n",
      "Episode: 15 Info: {'bid_submission_time': '2020-09-28 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 330026.86, 'total_profit': 573.63, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 5.207998}}\n",
      "Episode: 16 Info: {'bid_submission_time': '2020-09-29 05:00:00+00:00', 'step_reward': 25065.6, 'step_profit': 32.8, 'total_reward': 355092.46, 'total_profit': 606.43, 'TimeLimit.truncated': False, 'episode': {'r': 25065.6, 'l': 1, 't': 5.479027}}\n",
      "Episode: 17 Info: {'bid_submission_time': '2020-09-30 05:00:00+00:00', 'step_reward': 15016.56, 'step_profit': 8.28, 'total_reward': 370109.02, 'total_profit': 614.71, 'TimeLimit.truncated': False, 'episode': {'r': 15016.562, 'l': 1, 't': 5.72647}}\n",
      "Episode: 18 Info: {'bid_submission_time': '2020-10-01 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 364109.02, 'total_profit': 614.71, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 5.952457}}\n",
      "Episode: 19 Info: {'bid_submission_time': '2020-10-02 05:00:00+00:00', 'step_reward': 15116.78, 'step_profit': 58.39, 'total_reward': 379225.81, 'total_profit': 673.1, 'TimeLimit.truncated': False, 'episode': {'r': 15116.782, 'l': 1, 't': 6.195382}}\n",
      "Episode: 20 Info: {'bid_submission_time': '2020-10-03 05:00:00+00:00', 'step_reward': 25113.04, 'step_profit': 56.52, 'total_reward': 404338.85, 'total_profit': 729.62, 'TimeLimit.truncated': False, 'episode': {'r': 25113.04, 'l': 1, 't': 6.422383}}\n",
      "Episode: 21 Info: {'bid_submission_time': '2020-10-25 06:00:00+00:00', 'step_reward': 25085.8, 'step_profit': 42.9, 'total_reward': 429424.65, 'total_profit': 772.52, 'TimeLimit.truncated': False, 'episode': {'r': 25085.8, 'l': 1, 't': 6.662984}}\n",
      "Episode: 22 Info: {'bid_submission_time': '2020-10-26 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 423424.65, 'total_profit': 772.52, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 6.870338}}\n",
      "Episode: 23 Info: {'bid_submission_time': '2020-10-27 06:00:00+00:00', 'step_reward': 25078.0, 'step_profit': 39.0, 'total_reward': 448502.65, 'total_profit': 811.52, 'TimeLimit.truncated': False, 'episode': {'r': 25078.0, 'l': 1, 't': 7.102851}}\n",
      "Episode: 24 Info: {'bid_submission_time': '2020-10-28 06:00:00+00:00', 'step_reward': 56191.0, 'step_profit': 76.0, 'total_reward': 504693.65, 'total_profit': 926.52, 'TimeLimit.truncated': False, 'episode': {'r': 56191.0, 'l': 1, 't': 7.362915}}\n",
      "Episode: 25 Info: {'bid_submission_time': '2020-10-29 06:00:00+00:00', 'step_reward': 25086.0, 'step_profit': 43.0, 'total_reward': 529779.65, 'total_profit': 969.52, 'TimeLimit.truncated': False, 'episode': {'r': 25086.0, 'l': 1, 't': 7.611024}}\n",
      "Episode: 26 Info: {'bid_submission_time': '2020-10-30 06:00:00+00:00', 'step_reward': 25084.0, 'step_profit': 42.0, 'total_reward': 554863.65, 'total_profit': 1011.52, 'TimeLimit.truncated': False, 'episode': {'r': 25084.0, 'l': 1, 't': 7.871873}}\n",
      "Episode: 27 Info: {'bid_submission_time': '2020-10-31 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 548863.65, 'total_profit': 1011.52, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 8.122506}}\n",
      "Episode: 28 Info: {'bid_submission_time': '2020-11-22 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 542863.65, 'total_profit': 1011.52, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 8.421526}}\n",
      "Episode: 29 Info: {'bid_submission_time': '2020-11-23 06:00:00+00:00', 'step_reward': 56097.66, 'step_profit': 37.83, 'total_reward': 598961.31, 'total_profit': 1071.35, 'TimeLimit.truncated': False, 'episode': {'r': 56097.66, 'l': 1, 't': 8.714923}}\n",
      "Episode: 30 Info: {'bid_submission_time': '2020-11-24 06:00:00+00:00', 'step_reward': 56119.29, 'step_profit': 47.27, 'total_reward': 655080.6, 'total_profit': 1143.37, 'TimeLimit.truncated': False, 'episode': {'r': 56119.29, 'l': 1, 't': 8.966776}}\n",
      "Episode: 31 Info: {'bid_submission_time': '2020-11-25 06:00:00+00:00', 'step_reward': 56142.56, 'step_profit': 58.52, 'total_reward': 711223.16, 'total_profit': 1227.41, 'TimeLimit.truncated': False, 'episode': {'r': 56142.56, 'l': 1, 't': 9.222718}}\n",
      "Episode: 32 Info: {'bid_submission_time': '2020-11-26 06:00:00+00:00', 'step_reward': 25055.68, 'step_profit': 27.84, 'total_reward': 736278.84, 'total_profit': 1255.25, 'TimeLimit.truncated': False, 'episode': {'r': 25055.68, 'l': 1, 't': 9.467585}}\n",
      "Episode: 33 Info: {'bid_submission_time': '2020-11-27 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 730278.84, 'total_profit': 1255.25, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 9.676923}}\n",
      "Episode: 34 Info: {'bid_submission_time': '2020-11-28 06:00:00+00:00', 'step_reward': 87278.48, 'step_profit': 87.52, 'total_reward': 817557.32, 'total_profit': 1446.21, 'TimeLimit.truncated': False, 'episode': {'r': 87278.48, 'l': 1, 't': 10.074308}}\n",
      "Episode: 35 Info: {'bid_submission_time': '2020-12-20 06:00:00+00:00', 'step_reward': 25067.88, 'step_profit': 33.94, 'total_reward': 842625.2, 'total_profit': 1480.15, 'TimeLimit.truncated': False, 'episode': {'r': 25067.88, 'l': 1, 't': 10.413399}}\n",
      "Episode: 36 Info: {'bid_submission_time': '2020-12-21 06:00:00+00:00', 'step_reward': 87319.04, 'step_profit': 98.8, 'total_reward': 929944.24, 'total_profit': 1700.39, 'TimeLimit.truncated': False, 'episode': {'r': 87319.04, 'l': 1, 't': 10.798223}}\n",
      "Episode: 37 Info: {'bid_submission_time': '2020-12-22 06:00:00+00:00', 'step_reward': 87184.64, 'step_profit': 60.76, 'total_reward': 1017128.88, 'total_profit': 1824.27, 'TimeLimit.truncated': False, 'episode': {'r': 87184.64, 'l': 1, 't': 11.199493}}\n",
      "Episode: 38 Info: {'bid_submission_time': '2020-12-23 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1011128.88, 'total_profit': 1824.27, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 11.484903}}\n",
      "Episode: 39 Info: {'bid_submission_time': '2020-12-24 06:00:00+00:00', 'step_reward': 25101.18, 'step_profit': 50.59, 'total_reward': 1036230.06, 'total_profit': 1874.86, 'TimeLimit.truncated': False, 'episode': {'r': 25101.18, 'l': 1, 't': 11.831695}}\n",
      "Episode: 40 Info: {'bid_submission_time': '2020-12-25 06:00:00+00:00', 'step_reward': 56278.0, 'step_profit': 111.2, 'total_reward': 1092508.06, 'total_profit': 2041.66, 'TimeLimit.truncated': False, 'episode': {'r': 56278.0, 'l': 1, 't': 12.451773}}\n",
      "Episode: 41 Info: {'bid_submission_time': '2020-12-26 06:00:00+00:00', 'step_reward': 56240.8, 'step_profit': 96.4, 'total_reward': 1148748.86, 'total_profit': 2186.06, 'TimeLimit.truncated': False, 'episode': {'r': 56240.8, 'l': 1, 't': 12.748621}}\n",
      "Episode: 42 Info: {'bid_submission_time': '2021-01-17 06:00:00+00:00', 'step_reward': 56102.0, 'step_profit': 39.5, 'total_reward': 1204850.86, 'total_profit': 2248.56, 'TimeLimit.truncated': False, 'episode': {'r': 56102.0, 'l': 1, 't': 13.028589}}\n",
      "Episode: 43 Info: {'bid_submission_time': '2021-01-18 06:00:00+00:00', 'step_reward': 25031.66, 'step_profit': 15.83, 'total_reward': 1229882.52, 'total_profit': 2264.39, 'TimeLimit.truncated': False, 'episode': {'r': 25031.66, 'l': 1, 't': 13.268915}}\n",
      "Episode: 44 Info: {'bid_submission_time': '2021-01-19 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1223882.52, 'total_profit': 2264.39, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 13.513892}}\n",
      "Episode: 45 Info: {'bid_submission_time': '2021-01-20 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1217882.52, 'total_profit': 2264.39, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 13.741822}}\n",
      "Episode: 46 Info: {'bid_submission_time': '2021-01-21 06:00:00+00:00', 'step_reward': 25041.04, 'step_profit': 20.52, 'total_reward': 1242923.56, 'total_profit': 2284.91, 'TimeLimit.truncated': False, 'episode': {'r': 25041.04, 'l': 1, 't': 13.988141}}\n",
      "Episode: 47 Info: {'bid_submission_time': '2021-01-22 06:00:00+00:00', 'step_reward': 25034.0, 'step_profit': 17.0, 'total_reward': 1267957.56, 'total_profit': 2301.91, 'TimeLimit.truncated': False, 'episode': {'r': 25034.0, 'l': 1, 't': 14.222488}}\n",
      "Episode: 48 Info: {'bid_submission_time': '2021-01-23 06:00:00+00:00', 'step_reward': 25069.52, 'step_profit': 34.76, 'total_reward': 1293027.08, 'total_profit': 2336.67, 'TimeLimit.truncated': False, 'episode': {'r': 25069.52, 'l': 1, 't': 14.558383}}\n",
      "Episode: 49 Info: {'bid_submission_time': '2021-02-14 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1287027.08, 'total_profit': 2336.67, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 14.842281}}\n",
      "Episode: 50 Info: {'bid_submission_time': '2021-02-15 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1281027.08, 'total_profit': 2336.67, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 15.0818}}\n",
      "Episode: 51 Info: {'bid_submission_time': '2021-02-16 06:00:00+00:00', 'step_reward': 87198.07, 'step_profit': 61.85, 'total_reward': 1368225.15, 'total_profit': 2472.89, 'TimeLimit.truncated': False, 'episode': {'r': 87198.07, 'l': 1, 't': 15.636375}}\n",
      "Episode: 52 Info: {'bid_submission_time': '2021-02-17 06:00:00+00:00', 'step_reward': 56096.0, 'step_profit': 37.0, 'total_reward': 1424321.15, 'total_profit': 2531.89, 'TimeLimit.truncated': False, 'episode': {'r': 56096.0, 'l': 1, 't': 15.936461}}\n",
      "Episode: 53 Info: {'bid_submission_time': '2021-02-18 06:00:00+00:00', 'step_reward': 25044.42, 'step_profit': 22.21, 'total_reward': 1449365.57, 'total_profit': 2554.1, 'TimeLimit.truncated': False, 'episode': {'r': 25044.42, 'l': 1, 't': 16.172748}}\n",
      "Episode: 54 Info: {'bid_submission_time': '2021-02-19 06:00:00+00:00', 'step_reward': 25084.0, 'step_profit': 42.0, 'total_reward': 1474449.57, 'total_profit': 2596.1, 'TimeLimit.truncated': False, 'episode': {'r': 25084.0, 'l': 1, 't': 16.40908}}\n",
      "Episode: 55 Info: {'bid_submission_time': '2021-02-20 06:00:00+00:00', 'step_reward': 25046.08, 'step_profit': 23.04, 'total_reward': 1499495.65, 'total_profit': 2619.14, 'TimeLimit.truncated': False, 'episode': {'r': 25046.08, 'l': 1, 't': 16.629342}}\n",
      "Episode: 56 Info: {'bid_submission_time': '2021-03-14 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1493495.65, 'total_profit': 2619.14, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 16.896111}}\n",
      "Episode: 57 Info: {'bid_submission_time': '2021-03-15 06:00:00+00:00', 'step_reward': 56114.48, 'step_profit': 44.16, 'total_reward': 1549610.13, 'total_profit': 2689.46, 'TimeLimit.truncated': False, 'episode': {'r': 56114.48, 'l': 1, 't': 17.202657}}\n",
      "Episode: 58 Info: {'bid_submission_time': '2021-03-16 06:00:00+00:00', 'step_reward': 87161.6, 'step_profit': 51.4, 'total_reward': 1636771.73, 'total_profit': 2799.66, 'TimeLimit.truncated': False, 'episode': {'r': 87161.6, 'l': 1, 't': 17.529531}}\n",
      "Episode: 59 Info: {'bid_submission_time': '2021-03-17 06:00:00+00:00', 'step_reward': 56090.56, 'step_profit': 34.32, 'total_reward': 1692862.29, 'total_profit': 2855.9, 'TimeLimit.truncated': False, 'episode': {'r': 56090.56, 'l': 1, 't': 17.816328}}\n",
      "Episode: 60 Info: {'bid_submission_time': '2021-03-18 06:00:00+00:00', 'step_reward': 25045.92, 'step_profit': 22.96, 'total_reward': 1717908.21, 'total_profit': 2878.86, 'TimeLimit.truncated': False, 'episode': {'r': 25045.92, 'l': 1, 't': 18.102319}}\n",
      "Episode: 61 Info: {'bid_submission_time': '2021-03-19 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1711908.21, 'total_profit': 2878.86, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 18.359534}}\n",
      "Episode: 62 Info: {'bid_submission_time': '2021-03-20 06:00:00+00:00', 'step_reward': 56168.44, 'step_profit': 63.4, 'total_reward': 1768076.65, 'total_profit': 2983.9, 'TimeLimit.truncated': False, 'episode': {'r': 56168.44, 'l': 1, 't': 18.748126}}\n",
      "Episode: 63 Info: {'bid_submission_time': '2021-04-11 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1762076.65, 'total_profit': 2983.9, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 18.997546}}\n",
      "Episode: 64 Info: {'bid_submission_time': '2021-04-12 05:00:00+00:00', 'step_reward': 56300.12, 'step_profit': 120.28, 'total_reward': 1818376.77, 'total_profit': 3163.74, 'TimeLimit.truncated': False, 'episode': {'r': 56300.12, 'l': 1, 't': 19.258495}}\n",
      "Episode: 65 Info: {'bid_submission_time': '2021-04-13 05:00:00+00:00', 'step_reward': 87552.8, 'step_profit': 170.6, 'total_reward': 1905929.57, 'total_profit': 3545.94, 'TimeLimit.truncated': False, 'episode': {'r': 87552.8, 'l': 1, 't': 19.550136}}\n",
      "Episode: 66 Info: {'bid_submission_time': '2021-04-14 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 1899929.57, 'total_profit': 3545.94, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 19.781436}}\n",
      "Episode: 67 Info: {'bid_submission_time': '2021-04-15 05:00:00+00:00', 'step_reward': 25118.0, 'step_profit': 59.0, 'total_reward': 1925047.57, 'total_profit': 3604.94, 'TimeLimit.truncated': False, 'episode': {'r': 25118.0, 'l': 1, 't': 20.028527}}\n",
      "Episode: 68 Info: {'bid_submission_time': '2021-04-16 05:00:00+00:00', 'step_reward': 56258.6, 'step_profit': 101.1, 'total_reward': 1981306.17, 'total_profit': 3762.44, 'TimeLimit.truncated': False, 'episode': {'r': 56258.6, 'l': 1, 't': 20.339998}}\n",
      "Episode: 69 Info: {'bid_submission_time': '2021-04-17 05:00:00+00:00', 'step_reward': 25108.0, 'step_profit': 54.0, 'total_reward': 2006414.17, 'total_profit': 3816.44, 'TimeLimit.truncated': False, 'episode': {'r': 25108.0, 'l': 1, 't': 20.612169}}\n",
      "Episode: 70 Info: {'bid_submission_time': '2021-05-09 05:00:00+00:00', 'step_reward': 25150.4, 'step_profit': 75.2, 'total_reward': 2031564.57, 'total_profit': 3891.64, 'TimeLimit.truncated': False, 'episode': {'r': 25150.4, 'l': 1, 't': 20.863916}}\n",
      "Episode: 71 Info: {'bid_submission_time': '2021-05-10 05:00:00+00:00', 'step_reward': 25172.24, 'step_profit': 86.12, 'total_reward': 2056736.81, 'total_profit': 3977.76, 'TimeLimit.truncated': False, 'episode': {'r': 25172.24, 'l': 1, 't': 21.096946}}\n",
      "Episode: 72 Info: {'bid_submission_time': '2021-05-11 05:00:00+00:00', 'step_reward': 56377.08, 'step_profit': 150.04, 'total_reward': 2113113.89, 'total_profit': 4204.8, 'TimeLimit.truncated': False, 'episode': {'r': 56377.08, 'l': 1, 't': 21.431949}}\n",
      "Episode: 73 Info: {'bid_submission_time': '2021-05-12 05:00:00+00:00', 'step_reward': 25166.72, 'step_profit': 83.36, 'total_reward': 2138280.61, 'total_profit': 4288.16, 'TimeLimit.truncated': False, 'episode': {'r': 25166.72, 'l': 1, 't': 21.661621}}\n",
      "Episode: 74 Info: {'bid_submission_time': '2021-05-13 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2132280.61, 'total_profit': 4288.16, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 21.88477}}\n",
      "Episode: 75 Info: {'bid_submission_time': '2021-05-14 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2126280.61, 'total_profit': 4288.16, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 22.115552}}\n",
      "Episode: 76 Info: {'bid_submission_time': '2021-05-15 05:00:00+00:00', 'step_reward': 25162.54, 'step_profit': 81.27, 'total_reward': 2151443.15, 'total_profit': 4369.43, 'TimeLimit.truncated': False, 'episode': {'r': 25162.54, 'l': 1, 't': 22.366284}}\n",
      "Episode: 77 Info: {'bid_submission_time': '2021-06-06 05:00:00+00:00', 'step_reward': 25081.0, 'step_profit': 40.5, 'total_reward': 2176524.15, 'total_profit': 4409.93, 'TimeLimit.truncated': False, 'episode': {'r': 25081.0, 'l': 1, 't': 22.593281}}\n",
      "Episode: 78 Info: {'bid_submission_time': '2021-06-07 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2170524.15, 'total_profit': 4409.93, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 22.821091}}\n",
      "Episode: 79 Info: {'bid_submission_time': '2021-06-08 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2164524.15, 'total_profit': 4409.93, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 23.033015}}\n",
      "Episode: 80 Info: {'bid_submission_time': '2021-06-09 05:00:00+00:00', 'step_reward': 56323.0, 'step_profit': 132.52, 'total_reward': 2220847.15, 'total_profit': 4600.41, 'TimeLimit.truncated': False, 'episode': {'r': 56323.0, 'l': 1, 't': 23.284847}}\n",
      "Episode: 81 Info: {'bid_submission_time': '2021-06-10 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2214847.15, 'total_profit': 4600.41, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 23.483819}}\n",
      "Episode: 82 Info: {'bid_submission_time': '2021-06-11 05:00:00+00:00', 'step_reward': 25290.0, 'step_profit': 145.0, 'total_reward': 2240137.15, 'total_profit': 4745.41, 'TimeLimit.truncated': False, 'episode': {'r': 25290.0, 'l': 1, 't': 23.855331}}\n",
      "Episode: 83 Info: {'bid_submission_time': '2021-06-12 05:00:00+00:00', 'step_reward': 25096.0, 'step_profit': 48.0, 'total_reward': 2265233.15, 'total_profit': 4793.41, 'TimeLimit.truncated': False, 'episode': {'r': 25096.0, 'l': 1, 't': 24.105147}}\n",
      "Episode: 84 Info: {'bid_submission_time': '2021-07-04 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2259233.15, 'total_profit': 4793.41, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 24.325536}}\n",
      "Episode: 85 Info: {'bid_submission_time': '2021-07-05 05:00:00+00:00', 'step_reward': 25093.04, 'step_profit': 46.52, 'total_reward': 2284326.19, 'total_profit': 4839.93, 'TimeLimit.truncated': False, 'episode': {'r': 25093.04, 'l': 1, 't': 24.561599}}\n",
      "Episode: 86 Info: {'bid_submission_time': '2021-07-06 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2278326.19, 'total_profit': 4839.93, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 24.798395}}\n",
      "Episode: 87 Info: {'bid_submission_time': '2021-07-07 05:00:00+00:00', 'step_reward': 25096.72, 'step_profit': 48.36, 'total_reward': 2303422.91, 'total_profit': 4888.29, 'TimeLimit.truncated': False, 'episode': {'r': 25096.72, 'l': 1, 't': 25.014313}}\n",
      "Episode: 88 Info: {'bid_submission_time': '2021-07-08 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2297422.91, 'total_profit': 4888.29, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 25.259875}}\n",
      "Episode: 89 Info: {'bid_submission_time': '2021-07-09 05:00:00+00:00', 'step_reward': 56278.67, 'step_profit': 106.85, 'total_reward': 2353701.58, 'total_profit': 5060.11, 'TimeLimit.truncated': False, 'episode': {'r': 56278.67, 'l': 1, 't': 25.560144}}\n",
      "Episode: 90 Info: {'bid_submission_time': '2021-07-10 05:00:00+00:00', 'step_reward': 25159.76, 'step_profit': 79.88, 'total_reward': 2378861.34, 'total_profit': 5139.99, 'TimeLimit.truncated': False, 'episode': {'r': 25159.76, 'l': 1, 't': 25.792741}}\n",
      "Episode: 91 Info: {'bid_submission_time': '2021-08-01 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2372861.34, 'total_profit': 5139.99, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 26.012314}}\n",
      "Episode: 92 Info: {'bid_submission_time': '2021-08-02 05:00:00+00:00', 'step_reward': 25121.12, 'step_profit': 60.56, 'total_reward': 2397982.46, 'total_profit': 5200.55, 'TimeLimit.truncated': False, 'episode': {'r': 25121.12, 'l': 1, 't': 26.235664}}\n",
      "Episode: 93 Info: {'bid_submission_time': '2021-08-03 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2391982.46, 'total_profit': 5200.55, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 26.434583}}\n",
      "Episode: 94 Info: {'bid_submission_time': '2021-08-04 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2385982.46, 'total_profit': 5200.55, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 26.636106}}\n",
      "Episode: 95 Info: {'bid_submission_time': '2021-08-05 05:00:00+00:00', 'step_reward': 15054.05, 'step_profit': 27.03, 'total_reward': 2401036.51, 'total_profit': 5227.58, 'TimeLimit.truncated': False, 'episode': {'r': 15054.054, 'l': 1, 't': 26.859804}}\n",
      "Episode: 96 Info: {'bid_submission_time': '2021-08-06 05:00:00+00:00', 'step_reward': 15058.79, 'step_profit': 29.4, 'total_reward': 2416095.3, 'total_profit': 5256.98, 'TimeLimit.truncated': False, 'episode': {'r': 15058.795, 'l': 1, 't': 27.223659}}\n",
      "Episode: 97 Info: {'bid_submission_time': '2021-08-07 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2410095.3, 'total_profit': 5256.98, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 27.460435}}\n",
      "Episode: 98 Info: {'bid_submission_time': '2021-08-29 05:00:00+00:00', 'step_reward': 25091.2, 'step_profit': 45.6, 'total_reward': 2435186.5, 'total_profit': 5302.58, 'TimeLimit.truncated': False, 'episode': {'r': 25091.2, 'l': 1, 't': 27.746421}}\n",
      "Episode: 99 Info: {'bid_submission_time': '2021-08-30 05:00:00+00:00', 'step_reward': 25115.28, 'step_profit': 57.64, 'total_reward': 2460301.78, 'total_profit': 5360.22, 'TimeLimit.truncated': False, 'episode': {'r': 25115.28, 'l': 1, 't': 27.959787}}\n",
      "Episode: 100 Info: {'bid_submission_time': '2021-08-31 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2454301.78, 'total_profit': 5360.22, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 28.173734}}\n",
      "Episode: 101 Info: {'bid_submission_time': '2021-09-01 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2448301.78, 'total_profit': 5360.22, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 28.416926}}\n",
      "Episode: 102 Info: {'bid_submission_time': '2021-09-02 05:00:00+00:00', 'step_reward': 25152.0, 'step_profit': 76.0, 'total_reward': 2473453.78, 'total_profit': 5436.22, 'TimeLimit.truncated': False, 'episode': {'r': 25152.0, 'l': 1, 't': 28.7628}}\n",
      "Episode: 103 Info: {'bid_submission_time': '2021-09-03 05:00:00+00:00', 'step_reward': 25136.0, 'step_profit': 68.0, 'total_reward': 2498589.78, 'total_profit': 5504.22, 'TimeLimit.truncated': False, 'episode': {'r': 25136.0, 'l': 1, 't': 29.05735}}\n",
      "Episode: 104 Info: {'bid_submission_time': '2021-09-04 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2492589.78, 'total_profit': 5504.22, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 29.260485}}\n",
      "Episode: 105 Info: {'bid_submission_time': '2021-09-26 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2486589.78, 'total_profit': 5504.22, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 29.479279}}\n",
      "Episode: 106 Info: {'bid_submission_time': '2021-09-27 05:00:00+00:00', 'step_reward': 87826.4, 'step_profit': 252.6, 'total_reward': 2574416.18, 'total_profit': 6078.02, 'TimeLimit.truncated': False, 'episode': {'r': 87826.4, 'l': 1, 't': 29.778021}}\n",
      "Episode: 107 Info: {'bid_submission_time': '2021-09-28 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2568416.18, 'total_profit': 6078.02, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 29.989076}}\n",
      "Episode: 108 Info: {'bid_submission_time': '2021-09-29 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2562416.18, 'total_profit': 6078.02, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 30.215504}}\n",
      "Episode: 109 Info: {'bid_submission_time': '2021-09-30 05:00:00+00:00', 'step_reward': 15363.65, 'step_profit': 181.82, 'total_reward': 2577779.83, 'total_profit': 6259.84, 'TimeLimit.truncated': False, 'episode': {'r': 15363.648, 'l': 1, 't': 30.455143}}\n",
      "Episode: 110 Info: {'bid_submission_time': '2021-10-01 05:00:00+00:00', 'step_reward': 46745.28, 'step_profit': 281.76, 'total_reward': 2624525.11, 'total_profit': 6723.36, 'TimeLimit.truncated': False, 'episode': {'r': 46745.277, 'l': 1, 't': 30.736538}}\n",
      "Episode: 111 Info: {'bid_submission_time': '2021-10-03 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2618525.11, 'total_profit': 6723.36, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 30.983049}}\n",
      "Episode: 112 Info: {'bid_submission_time': '2021-10-24 05:00:00+00:00', 'step_reward': 25305.4, 'step_profit': 152.7, 'total_reward': 2643830.51, 'total_profit': 6876.06, 'TimeLimit.truncated': False, 'episode': {'r': 25305.4, 'l': 1, 't': 31.213256}}\n",
      "Episode: 113 Info: {'bid_submission_time': '2021-10-25 05:00:00+00:00', 'step_reward': 25272.88, 'step_profit': 136.44, 'total_reward': 2669103.39, 'total_profit': 7012.5, 'TimeLimit.truncated': False, 'episode': {'r': 25272.88, 'l': 1, 't': 31.462521}}\n",
      "Episode: 114 Info: {'bid_submission_time': '2021-10-26 05:00:00+00:00', 'step_reward': 56956.83, 'step_profit': 369.61, 'total_reward': 2726060.22, 'total_profit': 7599.72, 'TimeLimit.truncated': False, 'episode': {'r': 56956.83, 'l': 1, 't': 31.759151}}\n",
      "Episode: 115 Info: {'bid_submission_time': '2021-10-27 05:00:00+00:00', 'step_reward': 56938.18, 'step_profit': 363.38, 'total_reward': 2782998.4, 'total_profit': 8174.52, 'TimeLimit.truncated': False, 'episode': {'r': 56938.18, 'l': 1, 't': 32.030795}}\n",
      "Episode: 116 Info: {'bid_submission_time': '2021-10-28 05:00:00+00:00', 'step_reward': 25384.0, 'step_profit': 192.0, 'total_reward': 2808382.4, 'total_profit': 8366.52, 'TimeLimit.truncated': False, 'episode': {'r': 25384.0, 'l': 1, 't': 32.255127}}\n",
      "Episode: 117 Info: {'bid_submission_time': '2021-10-29 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2802382.4, 'total_profit': 8366.52, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 32.46419}}\n",
      "Episode: 118 Info: {'bid_submission_time': '2021-10-30 05:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 2796382.4, 'total_profit': 8366.52, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 32.667}}\n",
      "Episode: 119 Info: {'bid_submission_time': '2021-11-21 06:00:00+00:00', 'step_reward': 56382.57, 'step_profit': 157.19, 'total_reward': 2852764.97, 'total_profit': 8591.9, 'TimeLimit.truncated': False, 'episode': {'r': 56382.57, 'l': 1, 't': 33.069728}}\n",
      "Episode: 120 Info: {'bid_submission_time': '2021-11-22 06:00:00+00:00', 'step_reward': 56819.56, 'step_profit': 302.52, 'total_reward': 2909584.53, 'total_profit': 9108.94, 'TimeLimit.truncated': False, 'episode': {'r': 56819.56, 'l': 1, 't': 33.360766}}\n",
      "Episode: 121 Info: {'bid_submission_time': '2021-11-23 06:00:00+00:00', 'step_reward': 56741.64, 'step_profit': 278.98, 'total_reward': 2966326.17, 'total_profit': 9571.6, 'TimeLimit.truncated': False, 'episode': {'r': 56741.64, 'l': 1, 't': 33.638692}}\n",
      "Episode: 122 Info: {'bid_submission_time': '2021-11-24 06:00:00+00:00', 'step_reward': 56590.32, 'step_profit': 212.94, 'total_reward': 3022916.49, 'total_profit': 9948.98, 'TimeLimit.truncated': False, 'episode': {'r': 56590.32, 'l': 1, 't': 33.940676}}\n",
      "Episode: 123 Info: {'bid_submission_time': '2021-11-25 06:00:00+00:00', 'step_reward': 56889.6, 'step_profit': 322.2, 'total_reward': 3079806.09, 'total_profit': 10516.38, 'TimeLimit.truncated': False, 'episode': {'r': 56889.6, 'l': 1, 't': 34.201785}}\n",
      "Episode: 124 Info: {'bid_submission_time': '2021-11-26 06:00:00+00:00', 'step_reward': 56459.6, 'step_profit': 172.3, 'total_reward': 3136265.69, 'total_profit': 10803.68, 'TimeLimit.truncated': False, 'episode': {'r': 56459.6, 'l': 1, 't': 34.489301}}\n",
      "Episode: 125 Info: {'bid_submission_time': '2021-11-27 06:00:00+00:00', 'step_reward': 25132.0, 'step_profit': 66.0, 'total_reward': 3161397.69, 'total_profit': 10869.68, 'TimeLimit.truncated': False, 'episode': {'r': 25132.0, 'l': 1, 't': 34.759629}}\n",
      "Episode: 126 Info: {'bid_submission_time': '2021-12-19 06:00:00+00:00', 'step_reward': 25090.0, 'step_profit': 45.0, 'total_reward': 3186487.69, 'total_profit': 10914.68, 'TimeLimit.truncated': False, 'episode': {'r': 25090.0, 'l': 1, 't': 35.066444}}\n",
      "Episode: 127 Info: {'bid_submission_time': '2021-12-20 06:00:00+00:00', 'step_reward': 25060.0, 'step_profit': 30.0, 'total_reward': 3211547.69, 'total_profit': 10944.68, 'TimeLimit.truncated': False, 'episode': {'r': 25060.0, 'l': 1, 't': 35.388283}}\n",
      "Episode: 128 Info: {'bid_submission_time': '2021-12-21 06:00:00+00:00', 'step_reward': 25079.76, 'step_profit': 39.88, 'total_reward': 3236627.45, 'total_profit': 10984.56, 'TimeLimit.truncated': False, 'episode': {'r': 25079.76, 'l': 1, 't': 35.650539}}\n",
      "Episode: 129 Info: {'bid_submission_time': '2021-12-22 06:00:00+00:00', 'step_reward': 88256.96, 'step_profit': 406.88, 'total_reward': 3324884.41, 'total_profit': 11834.64, 'TimeLimit.truncated': False, 'episode': {'r': 88256.96, 'l': 1, 't': 36.162513}}\n",
      "Episode: 130 Info: {'bid_submission_time': '2021-12-23 06:00:00+00:00', 'step_reward': 25232.72, 'step_profit': 116.36, 'total_reward': 3350117.13, 'total_profit': 11951.0, 'TimeLimit.truncated': False, 'episode': {'r': 25232.72, 'l': 1, 't': 36.480313}}\n",
      "Episode: 131 Info: {'bid_submission_time': '2021-12-24 06:00:00+00:00', 'step_reward': 25231.2, 'step_profit': 115.6, 'total_reward': 3375348.33, 'total_profit': 12066.6, 'TimeLimit.truncated': False, 'episode': {'r': 25231.2, 'l': 1, 't': 36.817326}}\n",
      "Episode: 132 Info: {'bid_submission_time': '2021-12-25 06:00:00+00:00', 'step_reward': 56551.56, 'step_profit': 245.26, 'total_reward': 3431899.89, 'total_profit': 12372.9, 'TimeLimit.truncated': False, 'episode': {'r': 56551.56, 'l': 1, 't': 37.145763}}\n",
      "Episode: 133 Info: {'bid_submission_time': '2022-01-16 06:00:00+00:00', 'step_reward': 25266.8, 'step_profit': 133.4, 'total_reward': 3457166.69, 'total_profit': 12506.3, 'TimeLimit.truncated': False, 'episode': {'r': 25266.8, 'l': 1, 't': 37.420513}}\n",
      "Episode: 134 Info: {'bid_submission_time': '2022-01-17 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 3451166.69, 'total_profit': 12506.3, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 37.666823}}\n",
      "Episode: 135 Info: {'bid_submission_time': '2022-01-18 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 3445166.69, 'total_profit': 12506.3, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 37.875638}}\n",
      "Episode: 136 Info: {'bid_submission_time': '2022-01-19 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 3439166.69, 'total_profit': 12506.3, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 38.093419}}\n",
      "Episode: 137 Info: {'bid_submission_time': '2022-01-20 06:00:00+00:00', 'step_reward': 25040.0, 'step_profit': 20.0, 'total_reward': 3464206.69, 'total_profit': 12526.3, 'TimeLimit.truncated': False, 'episode': {'r': 25040.0, 'l': 1, 't': 38.356995}}\n",
      "Episode: 138 Info: {'bid_submission_time': '2022-01-21 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 3458206.69, 'total_profit': 12526.3, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 38.575439}}\n",
      "Episode: 139 Info: {'bid_submission_time': '2022-01-22 06:00:00+00:00', 'step_reward': -6000, 'step_profit': 0, 'total_reward': 3452206.69, 'total_profit': 12526.3, 'TimeLimit.truncated': False, 'episode': {'r': -6000.0, 'l': 1, 't': 38.796939}}\n",
      "Mean Run Reward: 24658.619214285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jan-Lukas.Pflaum/.virtualenvs/thesis/lib/python3.8/site-packages/nbformat/validator.py:315: DeprecationWarning:\n",
      "\n",
      "Passing a schema to Validator.iter_errors is deprecated and will be removed in a future release. Call validator.evolve(schema=new_schema).iter_errors(...) instead.\n",
      "\n",
      "/Users/Jan-Lukas.Pflaum/.virtualenvs/thesis/lib/python3.8/site-packages/wandb/sdk/lib/ipython.py:47: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>episode_reward</td><td>▁▁▁█▁▃▄▄██▄▄▄▄▁▄█▁▁▄▄▁▄▁▄█▁▃▄▄▁▃▄▁██▄▄▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>step_profit</td><td>▁▁▁▃▁▁▂▂▂▂▂▂▁▁▁▁▂▁▁▂▃▁▂▁▂▃▁▂▂▂▁▅▄▁▇█▂▄▁▁</td></tr><tr><td>step_reward</td><td>▁▁▁█▁▃▄▄██▄▄▄▄▁▄█▁▁▄▄▁▄▁▄█▁▃▄▄▁▃▄▁██▄▄▁▁</td></tr><tr><td>total_profit</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▆▆▇▇███</td></tr><tr><td>total_reward</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>episode</td><td>139</td></tr><tr><td>episode_reward</td><td>-6000</td></tr><tr><td>global_step</td><td>139</td></tr><tr><td>mean_run_reward</td><td>24658.61921</td></tr><tr><td>step_profit</td><td>0</td></tr><tr><td>step_reward</td><td>-6000</td></tr><tr><td>total_profit</td><td>12526.29686</td></tr><tr><td>total_reward</td><td>3452206.68874</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20220826_120604-3suzeunh<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20220826_120604-3suzeunh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=None)\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"SAC\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45654f7a-0f3d-43a1-9376-6dd09f6b5834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-VPP-Evaluation/runs/3suzeunh ... done.\n"
     ]
    }
   ],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8d29d-30ce-4197-b48c-b724b2c8c829",
   "metadata": {},
   "source": [
    "## A2C "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ef72a-bb38-4d04-87b9-485b7fd82235",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de4ea7-31ab-4c61-98e7-33317d79d7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=None)\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"A2C\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = A2C(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c6fa2-75d3-46f5-8746-27e933e218ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5aad3-fa4d-4d9d-84e5-ca95d4b71666",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255eea2-dd07-4ade-90bc-7bba9d975afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=None)\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"A2C\"] + experiment_tags, \n",
    "    job_type=\"eval\",\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20b6a8-4d95-4100-a184-69788ce3c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114da99c-13b3-45e9-8ec0-f8448d7cd69a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contrib packages: TQC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb52fea-bf32-4cad-904c-cff38159c74f",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a5179-c965-42e1-93b7-a2149e18149a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=None)\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TQC\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "\n",
    "policy_kwargs = dict(n_critics=2, n_quantiles=25)\n",
    "model = TQC(config['policy'], env, top_quantiles_to_drop_per_net=2, verbose=0, policy_kwargs=policy_kwargs)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e92660-7228-4dd5-abc0-c47242ffa283",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b85cc0-264e-4deb-84bb-365ec5c75853",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76cd545-bb27-414e-a0a3-e63bee99d996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=None)\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TQC\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation, deterministic=True)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50e223-07a5-42bc-bf1b-1648649d4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76662589-ed24-4f6c-aefe-d74d8c80eea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contrib packages: TRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b475d-2c52-448f-9dc3-507a7cd1eaa6",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86432aa7-ab9c-4648-ba3f-4b1b2ab64857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sb3_contrib import TRPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=None)\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TRPO\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = TRPO(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38878b19-3c6a-48e6-b9dd-e256bdb943e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b76e47-53a1-440b-972e-4a3ac0d5d968",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf863e-4168-4822-b8ea-ac462a895697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=None)\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TRPO\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation,  deterministic=True)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fe4ec-fa34-4313-ba19-97d95939dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8041122-244a-49b6-ad93-f484ad79652d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contrib packages: RecurrentPPO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ab4eb-728d-4949-9729-3640b794f936",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579e0f5-5eb0-4cbe-9f30-82049f9805ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sb3_contrib import RecurrentPPO\n",
    "import numpy as np\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=None)\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputLstmPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"RecurrentPPO\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = RecurrentPPO(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830f213-74e2-43a7-a24f-07514a3a2ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5a8cf-6a51-435b-9e40-92c238674217",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93dee6-1e6a-459d-8c0c-8e893955777c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=None)\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"RecurrentPPO\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    lstm_states = None\n",
    "    num_envs = 1\n",
    "    # Episode start signals are used to reset the lstm states\n",
    "    episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, lstm_states = model.predict(observation, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "        observation, reward, dones, info = eval_env.step(action)\n",
    "        episode_starts = dones\n",
    "        if done:\n",
    "            print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a7104-af25-4ec4-a6f1-ea595ec3e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0fb446-9ec5-4eb4-aebb-7f67edf5945e",
   "metadata": {},
   "source": [
    "## TD3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92227e40-1ef0-46a9-8b79-3c474b102033",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08083015-cb57-4510-a84c-9dd52124994c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=None)\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps # 1 iter = 557\n",
    "}\n",
    "\n",
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "#action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=0.34709686 * np.ones(n_actions))\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TD3\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = TD3(config['policy'],\n",
    "            env,\n",
    "            verbose=0,\n",
    "            tensorboard_log=f\"runs/ddpg\",\n",
    "            gamma=0.99,\n",
    "            batch_size=200, \n",
    "            buffer_size=1000000,\n",
    "            learning_rate=0.2456,\n",
    "            tau=0.001,\n",
    "            action_noise=action_noise,\n",
    "            policy_kwargs = {'net_arch': [64, 64]}\n",
    "           )\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b3913-c4a1-4521-a962-03b36acac482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05bbeb-906b-4f7c-9473-52a5bce82c43",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3694d5-33a3-4c75-94e8-5d2f0869a038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=None)\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TD3\"] + experiment_tags, \n",
    "    job_type=\"eval\",\n",
    "    #settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eddf0a-4b86-4199-af87-8a02afa8d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96e410-f147-424c-b274-5cb91d58f63c",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa6126-c250-4d39-b21f-fc32fa04005e",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281b68f-d7e7-4fff-879c-d558da2f94fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=None)\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"PPO\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = PPO(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957fc3e-b248-4f0f-a497-47643af02c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29272f27-6dd0-492e-a187-0373f68e526b",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65dbc2-a534-4141-9e52-46e77090aa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=None)\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"PPO\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7010536-1fb3-41a3-9735-b73a25cd5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d3eb4-1556-46f9-81e1-af6956e07e0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DDPG: Deep Deterministic Policy Gradient (DDPG) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f86ac-d5b2-498d-922f-50f64b6c5843",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2970c20-6c2e-4392-8972-b657b734e7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=None)\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma= 0.1 * np.ones(n_actions))\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"DDPG\"]+ experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = DDPG(config['policy'], env, action_noise=action_noise, verbose=0, tensorboard_log=f\"runs/ddpg\")\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37a144-afe9-4c1f-99be-16c7fb0171a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4dcac2-e0b7-4251-9e97-bba435f4ee23",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce413bca-a219-4562-aed3-5852fc79aa8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=None)\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"DDPG\"]+ experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043e517-9145-4271-9bc3-2f4e6bbf5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f57c7-3178-4897-8c7b-1de3d0525e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
