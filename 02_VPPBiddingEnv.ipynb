{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a32f4a0-96ea-48fe-a8ac-fa6adbef7f3e",
   "metadata": {},
   "source": [
    "# Run Agent in Environment with different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37105a1-c06c-445d-b9f9-afc70b8764e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Data \n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import numpy as np\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "# Algorithms \n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import TD3\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from sb3_contrib import TQC\n",
    "from sb3_contrib import TRPO\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from rl_zoo3 import linear_schedule\n",
    "\n",
    "from gym import make\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "\n",
    "import subprocess\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "from vpp_gym.vpp_gym.utils.register_env import register_env\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f10a6-c266-47b0-80cc-53cbbf95fe0e",
   "metadata": {},
   "source": [
    "## Seed Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3eda0-ce42-4c02-b13a-f4aefdebead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 44\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db6c67-ec11-492b-b29d-773764e7dc09",
   "metadata": {},
   "source": [
    "## Register the Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7d899-f638-44cf-8c5b-3f80b0723019",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_NAME = \"vpp_config_1_training.json\"\n",
    "\n",
    "register_env(config=CONFIG_NAME, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17256e7-0240-435d-a641-55d444a43406",
   "metadata": {},
   "source": [
    "## Test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72671bc0-33dd-4453-81b9-d86c8979a5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It will check your custom environment and output additional warnings if needed\n",
    "env_to_check = make('VPPBiddingEnv-TEST-v1', render_mode=None)\n",
    "check_env(env_to_check)\n",
    "env_to_check.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b9778-4b51-48b3-9b93-8fee865a49ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stable Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff546b2-3a85-4377-bc6d-75d3d60b41aa",
   "metadata": {},
   "source": [
    "### Offline Training and later sync logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787c994-9554-4c38-94df-ee1adafe2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"0cea1eee5f42654eca0de365f0acca116367c9b4\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc579db-a0a3-474c-bc1b-d139ac256d18",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1fcf70-09cd-497e-9d99-f04cbe27ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_algorithm(algorithm): \n",
    "    env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "    #env = make('VPPBiddingEnv-TUNING-logs-v1')\n",
    "    env = Monitor(env) \n",
    "    env = RecordEpisodeStatistics(env)\n",
    "    \n",
    "    if algorithm == \"R_PPO\": \n",
    "        policy = 'MultiInputLstmPolicy'\n",
    "    else: \n",
    "        policy = 'MultiInputPolicy'\n",
    "\n",
    "    wandb.init(\n",
    "        sync_tensorboard=True, \n",
    "        project=\"RL-VPP-Training\",\n",
    "        save_code=True,\n",
    "        entity=\"jlu237\", \n",
    "        tags=[algorithm] + EXPERIMENT_TAGS, \n",
    "        job_type=\"training\"\n",
    "    )\n",
    "    \n",
    "    model_params = HYPERPARAMS[algorithm]\n",
    "    model = ALGORITHMS[algorithm](policy, env, verbose=0,  seed = SEED , **model_params)\n",
    "    model.learn(total_timesteps=EXPERIMENT_TIMESTEPS,\n",
    "                log_interval=1,\n",
    "                progress_bar = True,\n",
    "                callback=WandbCallback(\n",
    "                    gradient_save_freq=1,\n",
    "                    verbose=0))\n",
    "    wandb.finish()\n",
    "    return_code = subprocess.run(\"wandb sync wandb/latest-run\", shell=True)\n",
    "    \n",
    "    return return_code, model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b85f6d-5c58-48e7-a799-cebc8f392eca",
   "metadata": {},
   "source": [
    "## Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3282c7-e8c2-4a16-a327-c6e3a7da08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(algorithm, model):\n",
    "    eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "    eval_env = Monitor(eval_env) \n",
    "    eval_env = RecordEpisodeStatistics(eval_env) \n",
    "\n",
    "    wandb.init(\n",
    "        sync_tensorboard=True, \n",
    "        project=\"RL-VPP-Evaluation\",\n",
    "        save_code=True,\n",
    "        entity=\"jlu237\", \n",
    "        tags=[algorithm] + EXPERIMENT_TAGS, \n",
    "        job_type=\"eval\",\n",
    "    )\n",
    "\n",
    "    episodes = 70\n",
    "    for i_episode in range(episodes):\n",
    "        observation = eval_env.reset()\n",
    "        if algorithm == \"R_PPO\":\n",
    "            lstm_states = None\n",
    "            num_envs = 1\n",
    "            # Episode start signals are used to reset the lstm states\n",
    "            episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "            for t in range(1):\n",
    "                action, lstm_states = model.predict(observation, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "                observation, reward, dones, info = eval_env.step(action)\n",
    "                episode_starts = dones\n",
    "        else: \n",
    "            for t in range(1):\n",
    "                action, _states = model.predict(observation, deterministic = True)\n",
    "                observation, reward, done, info = eval_env.step(action)\n",
    "\n",
    "    eval_env.close()\n",
    "    wandb.finish()\n",
    "    return_code = subprocess.run(\"wandb sync wandb/latest-run\", shell=True)\n",
    "    return return_code\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7de18040-a410-4d7a-8322-3a63475fb0ae",
   "metadata": {},
   "source": [
    "HYPERPARAMS = {\n",
    "    \n",
    "    \"A2C\": {},\n",
    "    \n",
    "    \"DDPG\": {},\n",
    "    \n",
    "    \"SAC\": {},\n",
    "    \n",
    "    \"PPO\": {},\n",
    "    \n",
    "    \"TD3\": {},\n",
    "    \n",
    "    #\"DQN\": {},\n",
    "    \n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": {},\n",
    "    \n",
    "    \"TRPO\": {},\n",
    "    \n",
    "    \"R_PPO\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735daa42-841e-406f-847a-23bf9f1f91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "#  NormalActionNoise(mean=[0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.],\n",
    "#                                              sigma=[0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106]\n",
    "#                                             )\n",
    "\n",
    "HYPERPARAMS = {\n",
    "    \n",
    "    \"A2C\": {},\n",
    "    \n",
    "    \"DDPG\": {},\n",
    "    \n",
    "    \"SAC\": {\n",
    "            'gradient_steps': -1,\n",
    "           },\n",
    "    \n",
    "    \"PPO\": {},\n",
    "    \n",
    "    \"TD3\": {},\n",
    "    \n",
    "    #\"DQN\": {},\n",
    "    \n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": {},\n",
    "    \n",
    "    \"TRPO\": {'learning_rate': 0.00006428106794995492,\n",
    "             'n_steps': 8,\n",
    "             'batch_size': 8,\n",
    "             'gamma': 0.95,\n",
    "             'cg_max_steps': 10,\n",
    "             'cg_damping': 0.01,\n",
    "             'line_search_shrinking_factor': 0.8,\n",
    "             'line_search_max_iter': 5,\n",
    "             'n_critic_updates': 25,\n",
    "             'gae_lambda': 0.98,\n",
    "             'normalize_advantage': False,\n",
    "             'use_sde': True,\n",
    "             'target_kl': 0.001,\n",
    "             'policy_kwargs': {'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}],\n",
    "                               'ortho_init': True,\n",
    "                               'activation_fn': nn.Tanh,\n",
    "                               'log_std_init': -1.882337250753788,\n",
    "                               'full_std': False,\n",
    "                               'sde_net_arch': [64, 64]},\n",
    "             'sde_sample_freq': 0},\n",
    "    \n",
    "    \"R_PPO\": {'learning_rate': 0.0018671792141252545,\n",
    "              'n_steps': 10,\n",
    "              'batch_size': 10,\n",
    "              'n_epochs': 5,\n",
    "              'gamma': 0.9999,\n",
    "              'gae_lambda': 0.9,\n",
    "              'clip_range': 0.2,\n",
    "              'normalize_advantage': True,\n",
    "              'ent_coef': 3.180891783226621e-06,\n",
    "              'vf_coef': 0.8521929103610445,\n",
    "              'max_grad_norm': 0.9,\n",
    "              'target_kl': 0.001,\n",
    "              'policy_kwargs': {'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}],\n",
    "                                'full_std': False,\n",
    "                                'activation_fn': nn.ELU,\n",
    "                                'ortho_init': False}}\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c6985b8-921c-44f6-8bce-7b24551300d2",
   "metadata": {},
   "source": [
    "# R_PPO\n",
    "\n",
    "{'learning_rate': linear_schedule(0.00047746791329352097),\n",
    "              'n_steps': 8,\n",
    "              'batch_size': 8,\n",
    "              'n_epochs': 10,\n",
    "              'gamma': 0.98,\n",
    "              'gae_lambda': 0.9,\n",
    "              'clip_range': 0.4,\n",
    "              'normalize_advantage': True,\n",
    "              'ent_coef': 0.03476154346691902,\n",
    "              'vf_coef': 0.6589086411755256,\n",
    "              'max_grad_norm': 5,\n",
    "              'target_kl': 0.1,\n",
    "              'policy_kwargs': {\n",
    "                  'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}],\n",
    "                  'full_std': True,\n",
    "                  'activation_fn': nn.Tanh,\n",
    "                  'ortho_init': True,\n",
    "                  'log_std_init': -2.303063874869516},\n",
    "              'sde_sample_freq': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc088d8b-c4fe-42a0-b2a5-ab31fa51c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHMS = {\n",
    "    \"A2C\": A2C,\n",
    "    \"DDPG\": DDPG,\n",
    "    \"PPO\": PPO,\n",
    "    \"SAC\": SAC,\n",
    "    \"TD3\": TD3,\n",
    "    #\"DQN\": DQN,\n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": TQC,\n",
    "    \"TRPO\": TRPO,\n",
    "    \"R_PPO\": RecurrentPPO,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4386e0-1c92-4777-b298-3e1e35b01648",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_TAGS = [\"config1_tuning\", \n",
    "                   \"AS: Box(12,)\", \n",
    "                   \"2785\",\n",
    "                   \"S44\",\n",
    "                   \"OS: Dict(7 features)\"\n",
    "                  ]\n",
    "\n",
    "EXPERIMENT_TIMESTEPS = 2785  #2785 #5570  #11140\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b29c-4008-4b4a-9405-679982f2bb93",
   "metadata": {},
   "source": [
    "## Train all Algorithms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcb1abd4-0d05-4beb-a8d0-d9b74e39dae2",
   "metadata": {},
   "source": [
    "algorithm_list = [\"SAC\", \"DDPG\", \"TD3\", \"TRPO\", \"R_PPO\",\"A2C\", \"PPO\", \"TQC\"]\n",
    "\n",
    "for algorithm in algorithm_list:\n",
    "    try:\n",
    "        print(\"now training \" + algorithm)\n",
    "        return_code, model = train_algorithm(algorithm) \n",
    "        print(\"training finished with : \" + str(return_code))\n",
    "        return_code = evaluate_algorithm(algorithm, model)\n",
    "        print(\"evaluation finished with : \" + str(return_code))        \n",
    "    except:\n",
    "        print(\"error occurred, next algo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc34a3c-438e-4efb-ac7a-653482b1affe",
   "metadata": {},
   "source": [
    "## Single Algorithm Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb405e2-37e9-4dc9-8687-c7d5583271b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ALGORITHM = \"PPO\"\n",
    "\n",
    "# MultiDiscrete 2: A2C, PPO, R_PPO, TRPO, M_PPO\n",
    "# MultiDiscrete 1: funktionierte nicht mit A2C und R_PPO, aber evtl mit PPO, TRPO ? \n",
    "\n",
    "print(\"now training \" + ALGORITHM)\n",
    "return_code, model = train_algorithm(ALGORITHM) \n",
    "print(\"training finished with : \" + str(return_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ceb116-2855-4038-82d7-e495aad110aa",
   "metadata": {},
   "source": [
    "## Single Algorithm Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3bb50-045d-49c3-8ed9-7cc164cab603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "return_code = evaluate_algorithm(ALGORITHM, model)\n",
    "print(\"evaluation finished with : \" + str(return_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34849d-7a52-4e06-ac99-c204f1cccf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
