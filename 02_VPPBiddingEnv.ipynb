{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a32f4a0-96ea-48fe-a8ac-fa6adbef7f3e",
   "metadata": {},
   "source": [
    "# Run Agent in Environment with different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37105a1-c06c-445d-b9f9-afc70b8764e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Data \n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import numpy as np\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "from gym import make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db6c67-ec11-492b-b29d-773764e7dc09",
   "metadata": {},
   "source": [
    "## Register the Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7d899-f638-44cf-8c5b-3f80b0723019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register\n",
    "   \n",
    "register(\n",
    "    id=\"VPPBiddingEnv-TRAIN-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"DEBUG\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"training\",\n",
    "            'render_mode' :\"human\", # \"human\", \"fast_training\" or None\n",
    "           }\n",
    ")\n",
    "\n",
    "register(\n",
    "    id=\"VPPBiddingEnv-EVAL-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"DEBUG\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"eval\",\n",
    "            'render_mode' :\"human\", # \"human\", \"fast_training\" or None\n",
    "           }\n",
    ")\n",
    "\n",
    "register(\n",
    "    id=\"VPPBiddingEnv-TEST-v1\",\n",
    "    entry_point='vpp-gym.vpp_gym.envs.vpp_env:VPPBiddingEnv',\n",
    "    max_episode_steps=1,\n",
    "    kwargs={'config_path': \"vpp_config_4.json\",\n",
    "            'log_level' : \"INFO\", # \"DEBUG\" , \"INFO\" or  \"WARNING\"\n",
    "            'env_type' :\"test\",\n",
    "            'render_mode' :\"human\", # \"human\", \"fast_training\" or None\n",
    "           }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17256e7-0240-435d-a641-55d444a43406",
   "metadata": {},
   "source": [
    "## Test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72671bc0-33dd-4453-81b9-d86c8979a5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "env_to_check = make('VPPBiddingEnv-TEST-v1', render_mode=None)\n",
    "check_env(env_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b9778-4b51-48b3-9b93-8fee865a49ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stable Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4386e0-1c92-4777-b298-3e1e35b01648",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_tags = [\"no_render_in_reset\", \"distance_reward_slots\", \"not_participated_reward\", \"new_slot_viz\" , \"weighted_step_reward_out_of_loop\"]\n",
    "experiment_timesteps = 2785"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff546b2-3a85-4377-bc6d-75d3d60b41aa",
   "metadata": {},
   "source": [
    "### Offline Training and later sync logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787c994-9554-4c38-94df-ee1adafe2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"0cea1eee5f42654eca0de365f0acca116367c9b4\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf65e36-b792-4eee-9dd3-5ddcae5b91cb",
   "metadata": {},
   "source": [
    "## SAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdce13-d9e6-49c4-8405-241856fbe544",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a05d95-6c52-4826-9484-bcc9e8306ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"SAC\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = SAC(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29214f-d5c9-4a8e-9bd1-ce2fb5bfc118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22814aa5-3352-4191-be75-438089e4c506",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbc69a-b0b1-436c-afbb-3d4016a8b197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"SAC\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            #print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45654f7a-0f3d-43a1-9376-6dd09f6b5834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8d29d-30ce-4197-b48c-b724b2c8c829",
   "metadata": {},
   "source": [
    "## A2C "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ef72a-bb38-4d04-87b9-485b7fd82235",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de4ea7-31ab-4c61-98e7-33317d79d7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"A2C\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = A2C(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c6fa2-75d3-46f5-8746-27e933e218ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5aad3-fa4d-4d9d-84e5-ca95d4b71666",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255eea2-dd07-4ade-90bc-7bba9d975afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"A2C\"] + experiment_tags, \n",
    "    job_type=\"eval\",\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            #print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20b6a8-4d95-4100-a184-69788ce3c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114da99c-13b3-45e9-8ec0-f8448d7cd69a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contrib packages: TQC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb52fea-bf32-4cad-904c-cff38159c74f",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a5179-c965-42e1-93b7-a2149e18149a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sb3_contrib import TQC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TQC\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "\n",
    "policy_kwargs = dict(n_critics=2, n_quantiles=25)\n",
    "model = TQC(config['policy'], env, top_quantiles_to_drop_per_net=2, verbose=0, policy_kwargs=policy_kwargs)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e92660-7228-4dd5-abc0-c47242ffa283",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b85cc0-264e-4deb-84bb-365ec5c75853",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76cd545-bb27-414e-a0a3-e63bee99d996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TQC\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation, deterministic=True)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            #print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50e223-07a5-42bc-bf1b-1648649d4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76662589-ed24-4f6c-aefe-d74d8c80eea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contrib packages: TRPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b475d-2c52-448f-9dc3-507a7cd1eaa6",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86432aa7-ab9c-4648-ba3f-4b1b2ab64857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sb3_contrib import TRPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TRPO\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = TRPO(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38878b19-3c6a-48e6-b9dd-e256bdb943e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b76e47-53a1-440b-972e-4a3ac0d5d968",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf863e-4168-4822-b8ea-ac462a895697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TRPO\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation,  deterministic=True)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            #print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fe4ec-fa34-4313-ba19-97d95939dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8041122-244a-49b6-ad93-f484ad79652d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contrib packages: RecurrentPPO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ab4eb-728d-4949-9729-3640b794f936",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579e0f5-5eb0-4cbe-9f30-82049f9805ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sb3_contrib import RecurrentPPO\n",
    "import numpy as np\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputLstmPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"RecurrentPPO\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = RecurrentPPO(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830f213-74e2-43a7-a24f-07514a3a2ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5a8cf-6a51-435b-9e40-92c238674217",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93dee6-1e6a-459d-8c0c-8e893955777c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"RecurrentPPO\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    lstm_states = None\n",
    "    num_envs = 1\n",
    "    # Episode start signals are used to reset the lstm states\n",
    "    episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, lstm_states = model.predict(observation, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "        observation, reward, dones, info = eval_env.step(action)\n",
    "        episode_starts = dones\n",
    "        if done:\n",
    "            #print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a7104-af25-4ec4-a6f1-ea595ec3e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0fb446-9ec5-4eb4-aebb-7f67edf5945e",
   "metadata": {},
   "source": [
    "## TD3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92227e40-1ef0-46a9-8b79-3c474b102033",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08083015-cb57-4510-a84c-9dd52124994c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps # 1 iter = 557\n",
    "}\n",
    "\n",
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "#action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=0.34709686 * np.ones(n_actions))\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TD3\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = TD3(config['policy'],\n",
    "            env,\n",
    "            verbose=0,\n",
    "            tensorboard_log=f\"runs/ddpg\",\n",
    "            gamma=0.99,\n",
    "            batch_size=200, \n",
    "            buffer_size=1000000,\n",
    "            learning_rate=0.2456,\n",
    "            tau=0.001,\n",
    "            action_noise=action_noise,\n",
    "            policy_kwargs = {'net_arch': [64, 64]}\n",
    "           )\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b3913-c4a1-4521-a962-03b36acac482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05bbeb-906b-4f7c-9473-52a5bce82c43",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3694d5-33a3-4c75-94e8-5d2f0869a038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"TD3\"] + experiment_tags, \n",
    "    job_type=\"eval\",\n",
    "    #settings=wandb.Settings(start_method=\"thread\")\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            #print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eddf0a-4b86-4199-af87-8a02afa8d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96e410-f147-424c-b274-5cb91d58f63c",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa6126-c250-4d39-b21f-fc32fa04005e",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281b68f-d7e7-4fff-879c-d558da2f94fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"PPO\"] + experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = PPO(config['policy'], env, verbose=0)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957fc3e-b248-4f0f-a497-47643af02c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29272f27-6dd0-492e-a187-0373f68e526b",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65dbc2-a534-4141-9e52-46e77090aa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"PPO\"] + experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            #print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7010536-1fb3-41a3-9735-b73a25cd5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d3eb4-1556-46f9-81e1-af6956e07e0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DDPG: Deep Deterministic Policy Gradient (DDPG) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f86ac-d5b2-498d-922f-50f64b6c5843",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2970c20-6c2e-4392-8972-b657b734e7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "env = Monitor(env) \n",
    "env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"policy\": 'MultiInputPolicy',\n",
    "    \"total_timesteps\": experiment_timesteps #557\n",
    "}\n",
    "\n",
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma= 0.1 * np.ones(n_actions))\n",
    "\n",
    "wandb.init(\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Training\",\n",
    "    monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"DDPG\"]+ experiment_tags, \n",
    "    job_type=\"training\"\n",
    ")\n",
    "\n",
    "model = DDPG(config['policy'], env, action_noise=action_noise, verbose=0, tensorboard_log=f\"runs/ddpg\")\n",
    "\n",
    "model.learn(total_timesteps=config['total_timesteps'],\n",
    "            log_interval=1,\n",
    "            callback=WandbCallback(\n",
    "                gradient_save_freq=1,\n",
    "                verbose=0))\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37a144-afe9-4c1f-99be-16c7fb0171a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4dcac2-e0b7-4251-9e97-bba435f4ee23",
   "metadata": {},
   "source": [
    "### Eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce413bca-a219-4562-aed3-5852fc79aa8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B\n",
    "    project=\"RL-VPP-Evaluation\",\n",
    "    #monitor_gym=True,       # automatically upload gym environements' videos\n",
    "    save_code=True,\n",
    "    entity=\"jlu237\", \n",
    "    tags=[\"DDPG\"]+ experiment_tags, \n",
    "    job_type=\"eval\"\n",
    ")\n",
    "\n",
    "\n",
    "tbl = wandb.Table(columns=[\"episode\", \"bid_submission_time\"])\n",
    "\n",
    "episodes = 140\n",
    "\n",
    "for i_episode in range(episodes):\n",
    "    observation = eval_env.reset()\n",
    "    for t in range(1):\n",
    "        eval_env.render()\n",
    "        logging.debug(\"observation : \" + str(observation))\n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = eval_env.step(action)\n",
    "        if done:\n",
    "            #print('Episode: {} Info: {}'.format(i_episode, info))\n",
    "            tbl.add_data(i_episode, info[\"bid_submission_time\"])\n",
    "            wandb.log({\"episode_reward\": reward,\n",
    "                       \"episode\": i_episode\n",
    "                      })\n",
    "            \n",
    "            break\n",
    "wandb.log({\"bid_submission_time\" : tbl})\n",
    "\n",
    "eval_env.close()\n",
    "mean_run_reward = info[\"total_reward\"] / episodes\n",
    "\n",
    "wandb.run.summary[\"mean_run_reward\"] = mean_run_reward\n",
    "print(\"Mean Run Reward: \" + str(mean_run_reward))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043e517-9145-4271-9bc3-2f4e6bbf5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync wandb/latest-run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
