{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a32f4a0-96ea-48fe-a8ac-fa6adbef7f3e",
   "metadata": {},
   "source": [
    "# Run Agent in Environment with different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37105a1-c06c-445d-b9f9-afc70b8764e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Data \n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import numpy as np\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "# Algorithms \n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import TD3\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from sb3_contrib import TQC\n",
    "from sb3_contrib import TRPO\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from rl_zoo3 import linear_schedule\n",
    "\n",
    "from gym import make\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "\n",
    "import subprocess\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "from vpp_gym.vpp_gym.utils.register_env import register_env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f10a6-c266-47b0-80cc-53cbbf95fe0e",
   "metadata": {},
   "source": [
    "## Seed Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c3eda0-ce42-4c02-b13a-f4aefdebead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db6c67-ec11-492b-b29d-773764e7dc09",
   "metadata": {},
   "source": [
    "## Register the Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de7d899-f638-44cf-8c5b-3f80b0723019",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_NAME = \"vpp_config_2.json\"\n",
    "\n",
    "register_env(config=CONFIG_NAME, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17256e7-0240-435d-a641-55d444a43406",
   "metadata": {},
   "source": [
    "## Test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72671bc0-33dd-4453-81b9-d86c8979a5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_step: initial // slot: initial  log level = warning\n",
      "log_step: 0 slot: None logging_step: 0\n"
     ]
    }
   ],
   "source": [
    "# It will check your custom environment and output additional warnings if needed\n",
    "env_to_check = make('VPPBiddingEnv-TEST-v1', render_mode=None)\n",
    "check_env(env_to_check)\n",
    "env_to_check.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b9778-4b51-48b3-9b93-8fee865a49ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stable Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff546b2-3a85-4377-bc6d-75d3d60b41aa",
   "metadata": {},
   "source": [
    "### Offline Training and later sync logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5787c994-9554-4c38-94df-ee1adafe2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"0cea1eee5f42654eca0de365f0acca116367c9b4\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc579db-a0a3-474c-bc1b-d139ac256d18",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1fcf70-09cd-497e-9d99-f04cbe27ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_algorithm(algorithm): \n",
    "    #env = make('VPPBiddingEnv-TRAIN-v1', render_mode=\"human\")\n",
    "    env = make('VPPBiddingEnv-TUNING-v1')\n",
    "    env = Monitor(env) \n",
    "    env = RecordEpisodeStatistics(env)\n",
    "\n",
    "    if algorithm == \"R_PPO\": \n",
    "        policy = 'MultiInputLstmPolicy'\n",
    "    else: \n",
    "        policy = 'MultiInputPolicy'\n",
    "\n",
    "    wandb.init(\n",
    "        sync_tensorboard=True, \n",
    "        project=\"RL-VPP-Training\",\n",
    "        save_code=True,\n",
    "        entity=\"jlu237\", \n",
    "        tags=[algorithm] + EXPERIMENT_TAGS, \n",
    "        job_type=\"training\"\n",
    "    )\n",
    "    \n",
    "    model_params = HYPERPARAMS[algorithm]\n",
    "    model = ALGORITHMS[algorithm](policy, env, verbose=0,  seed = SEED, **model_params)\n",
    "    model.learn(total_timesteps=EXPERIMENT_TIMESTEPS,\n",
    "                log_interval=1,\n",
    "                progress_bar = True,\n",
    "                callback=WandbCallback(\n",
    "                    gradient_save_freq=1,\n",
    "                    verbose=0))\n",
    "    wandb.finish()\n",
    "    return_code = subprocess.run(\"wandb sync wandb/latest-run\", shell=True)\n",
    "    \n",
    "    return return_code, model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b85f6d-5c58-48e7-a799-cebc8f392eca",
   "metadata": {},
   "source": [
    "## Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd3282c7-e8c2-4a16-a327-c6e3a7da08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(algorithm, model):\n",
    "    eval_env = make('VPPBiddingEnv-EVAL-v1', render_mode=\"human\")\n",
    "    eval_env = Monitor(eval_env) \n",
    "    eval_env = RecordEpisodeStatistics(eval_env) \n",
    "\n",
    "    wandb.init(\n",
    "        sync_tensorboard=True, \n",
    "        project=\"RL-VPP-Evaluation\",\n",
    "        save_code=True,\n",
    "        entity=\"jlu237\", \n",
    "        tags=[algorithm] + EXPERIMENT_TAGS, \n",
    "        job_type=\"eval\",\n",
    "    )\n",
    "\n",
    "    episodes = 140\n",
    "    for i_episode in range(episodes):\n",
    "        observation = eval_env.reset()\n",
    "        if algorithm == \"R_PPO\":\n",
    "            lstm_states = None\n",
    "            num_envs = 1\n",
    "            # Episode start signals are used to reset the lstm states\n",
    "            episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "            for t in range(1):\n",
    "                action, lstm_states = model.predict(observation, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "                observation, reward, dones, info = eval_env.step(action)\n",
    "                episode_starts = dones\n",
    "        else: \n",
    "            for t in range(1):\n",
    "                action, _states = model.predict(observation, deterministic = True)\n",
    "                observation, reward, done, info = eval_env.step(action)\n",
    "\n",
    "    eval_env.close()\n",
    "    wandb.finish()\n",
    "    return_code = subprocess.run(\"wandb sync wandb/latest-run\", shell=True)\n",
    "    return return_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a2665c9-7951-4d7b-8db6-63d6a0b2d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "#  NormalActionNoise(mean=[0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.],\n",
    "#                                              sigma=[0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106]\n",
    "#                                             )\n",
    "\n",
    "HYPERPARAMS = {\n",
    "    \n",
    "    \"A2C\": {},\n",
    "    \n",
    "    \"DDPG\": {},\n",
    "    \n",
    "    \"SAC\": {'learning_rate': 0.010591885782399316,\n",
    "            'batch_size': 100,\n",
    "            'buffer_size': 100000,\n",
    "            'learning_starts': 10, \n",
    "            'train_freq': 16,\n",
    "            'gradient_steps': 2,\n",
    "            'ent_coef': 0.05,\n",
    "            'tau': 0.005,\n",
    "            'gamma': 0.98,\n",
    "            'policy_kwargs': {\n",
    "                'net_arch': [256, 256],\n",
    "                'activation_fn': nn.Tanh,\n",
    "                'log_std_init': -3.4586660996768894,\n",
    "                'use_sde': False},\n",
    "            'sde_sample_freq': 0,\n",
    "            'target_entropy': -10,\n",
    "            'action_noise': NormalActionNoise(mean=[0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.],\n",
    "                                              sigma=[0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106,0.15087106]\n",
    "                                             )\n",
    "           },\n",
    "    \n",
    "    \"PPO\": {},\n",
    "    \n",
    "    \"TD3\": {},\n",
    "    \n",
    "    #\"DQN\": {},\n",
    "    \n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": {},\n",
    "    \n",
    "    \"TRPO\": {'learning_rate': linear_schedule(0.04052181863791221),\n",
    "             'n_steps': 2,\n",
    "             'batch_size': 2,\n",
    "             'gamma': 0.995,\n",
    "             'cg_max_steps': 25,\n",
    "             'cg_damping': 0.05,\n",
    "             'line_search_shrinking_factor': 0.6,\n",
    "             'line_search_max_iter': 5,\n",
    "             'n_critic_updates': 20,\n",
    "             'gae_lambda': 0.8,\n",
    "             'normalize_advantage': False, \n",
    "             'use_sde': False,\n",
    "             'target_kl': 0.1,\n",
    "             'policy_kwargs': {'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}],\n",
    "                               'ortho_init': True,\n",
    "                               'activation_fn': nn.ELU}},\n",
    "    \n",
    "    \"R_PPO\": {'learning_rate': 0.0018671792141252545,\n",
    "              'n_steps': 10,\n",
    "              'batch_size': 10,\n",
    "              'n_epochs': 5,\n",
    "              'gamma': 0.9999,\n",
    "              'gae_lambda': 0.9,\n",
    "              'clip_range': 0.2,\n",
    "              'normalize_advantage': True,\n",
    "              'ent_coef': 3.180891783226621e-06,\n",
    "              'vf_coef': 0.8521929103610445,\n",
    "              'max_grad_norm': 0.9,\n",
    "              'target_kl': 0.001,\n",
    "              'policy_kwargs': {'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}],\n",
    "                                'full_std': False,\n",
    "                                'activation_fn': nn.ELU,\n",
    "                                'ortho_init': False}}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ac705b-80c7-4411-a946-60b3947e866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': <function rl_zoo3.utils.linear_schedule.<locals>.func(progress_remaining: float) -> float>,\n",
       " 'n_steps': 8,\n",
       " 'batch_size': 8,\n",
       " 'n_epochs': 10,\n",
       " 'gamma': 0.98,\n",
       " 'gae_lambda': 0.9,\n",
       " 'clip_range': 0.4,\n",
       " 'normalize_advantage': True,\n",
       " 'ent_coef': 0.03476154346691902,\n",
       " 'vf_coef': 0.6589086411755256,\n",
       " 'max_grad_norm': 5,\n",
       " 'target_kl': 0.1,\n",
       " 'policy_kwargs': {'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}],\n",
       "  'full_std': True,\n",
       "  'activation_fn': torch.nn.modules.activation.Tanh,\n",
       "  'ortho_init': True,\n",
       "  'log_std_init': -2.303063874869516},\n",
       " 'sde_sample_freq': -1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R_PPO\n",
    "\n",
    "{'learning_rate': linear_schedule(0.00047746791329352097),\n",
    "              'n_steps': 8,\n",
    "              'batch_size': 8,\n",
    "              'n_epochs': 10,\n",
    "              'gamma': 0.98,\n",
    "              'gae_lambda': 0.9,\n",
    "              'clip_range': 0.4,\n",
    "              'normalize_advantage': True,\n",
    "              'ent_coef': 0.03476154346691902,\n",
    "              'vf_coef': 0.6589086411755256,\n",
    "              'max_grad_norm': 5,\n",
    "              'target_kl': 0.1,\n",
    "              'policy_kwargs': {\n",
    "                  'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}],\n",
    "                  'full_std': True,\n",
    "                  'activation_fn': nn.Tanh,\n",
    "                  'ortho_init': True,\n",
    "                  'log_std_init': -2.303063874869516},\n",
    "              'sde_sample_freq': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc088d8b-c4fe-42a0-b2a5-ab31fa51c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHMS = {\n",
    "    \"A2C\": A2C,\n",
    "    \"DDPG\": DDPG,\n",
    "    \"PPO\": PPO,\n",
    "    \"SAC\": SAC,\n",
    "    \"TD3\": TD3,\n",
    "    #\"DQN\": DQN,\n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": TQC,\n",
    "    \"TRPO\": TRPO,\n",
    "    \"R_PPO\": RecurrentPPO,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f4386e0-1c92-4777-b298-3e1e35b01648",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_TAGS = [\"^0.4\",\n",
    "                   \"only_asset_data_FCR_total\",\n",
    "                   \"config2\", \"rew=1 if not part\",\n",
    "                   \"H1,2,3 + 0.5 FCR\",\n",
    "                   \"less_observations\",\n",
    "                   \"AS: MultiDiscrete\"]\n",
    "EXPERIMENT_TIMESTEPS = 11140 #2785 #5570  #2785 =  557 * 5 cycles of summer 2022 - summer 2022, 10 cycles = 5570\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b29c-4008-4b4a-9405-679982f2bb93",
   "metadata": {},
   "source": [
    "## Train all Algorithms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f12653bf-0f0f-4ce5-bb6a-dfc9b0fc7e29",
   "metadata": {},
   "source": [
    "algorithm_list = [\"SAC\", \"DDPG\", \"TD3\", \"TRPO\", \"R_PPO\",\"A2C\", \"PPO\", \"TQC\"]\n",
    "\n",
    "for algorithm in algorithm_list:\n",
    "    try:\n",
    "        print(\"now training \" + algorithm)\n",
    "        return_code, model = train_algorithm(algorithm) \n",
    "        print(\"training finished with : \" + str(return_code))\n",
    "        return_code = evaluate_algorithm(algorithm, model)\n",
    "        print(\"evaluation finished with : \" + str(return_code))        \n",
    "    except:\n",
    "        print(\"error occurred, next algo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc34a3c-438e-4efb-ac7a-653482b1affe",
   "metadata": {},
   "source": [
    "## Single Algorithm Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f527affb-3f04-4963-94eb-2d0d0f581241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training TRPO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c82ef756d44fb8b4de4fff946cf6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "KeyboardInterrupt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "KeyboardInterrupt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ALGORITHM = \"TRPO\"\n",
    "\n",
    "# MultiDiscrete 2: A2C, PPO, R_PPO, TRPO, M_PPO\n",
    "# MultiDiscrete 1: funktionierte nicht mit A2C und R_PPO, aber evtl mit PPO, TRPO ? \n",
    "\n",
    "print(\"now training \" + ALGORITHM)\n",
    "return_code, model = train_algorithm(ALGORITHM) \n",
    "print(\"training finished with : \" + str(return_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ceb116-2855-4038-82d7-e495aad110aa",
   "metadata": {},
   "source": [
    "## Single Algorithm Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa432597-71b7-458e-a04b-bca490b6afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_code = evaluate_algorithm(ALGORITHM, model)\n",
    "print(\"evaluation finished with : \" + str(return_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34849d-7a52-4e06-ac99-c204f1cccf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
